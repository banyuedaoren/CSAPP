1
00:00:00,000 --> 00:00:06,779
good afternoon everyone welcome to 213

2
00:00:03,240 --> 00:00:10,759
it's good to see you just a reminder

3
00:00:06,779 --> 00:00:14,429
that your attack lab is due tonight at

4
00:00:10,759 --> 00:00:18,180
11:59 p.m. you have one great day for

5
00:00:14,429 --> 00:00:21,449
this for this lab and cache lab we'll go

6
00:00:18,180 --> 00:00:22,890
out and write about the same time now

7
00:00:21,449 --> 00:00:27,150
it's going to be a little tight for cash

8
00:00:22,890 --> 00:00:28,560
lab it'll be due next Thursday so you

9
00:00:27,150 --> 00:00:33,840
might want to you might want to get

10
00:00:28,560 --> 00:00:35,489
started on that soon b2 last lecture we

11
00:00:33,840 --> 00:00:38,160
learned about the memory hierarchy and

12
00:00:35,489 --> 00:00:42,440
the idea of caching today we're going to

13
00:00:38,160 --> 00:00:45,539
look at a very important kind of cache

14
00:00:42,440 --> 00:00:49,079
which is a which are called cache

15
00:00:45,539 --> 00:00:50,550
memories and they're very important to

16
00:00:49,079 --> 00:00:52,050
you as a programmer because they can

17
00:00:50,550 --> 00:00:54,270
have such a big impact on the

18
00:00:52,050 --> 00:00:56,160
performance of your program so if you

19
00:00:54,270 --> 00:00:59,399
know about the existence of these cache

20
00:00:56,160 --> 00:01:00,629
memories and you know how they work as a

21
00:00:59,399 --> 00:01:04,010
programmer you'll be able to take

22
00:01:00,629 --> 00:01:04,010
advantage of that in your programs

23
00:01:07,510 --> 00:01:12,950
so last time we looked at that the

24
00:01:10,730 --> 00:01:20,350
memory hierarchy is a collection of

25
00:01:12,950 --> 00:01:20,350
storage devices with smaller costlier

26
00:01:20,590 --> 00:01:28,790
devices that the and faster devices at

27
00:01:23,210 --> 00:01:31,210
the top and slower cheaper and much

28
00:01:28,790 --> 00:01:35,200
larger devices at the at the bottom and

29
00:01:31,210 --> 00:01:37,970
then at each level in this hierarchy a

30
00:01:35,200 --> 00:01:42,430
the device that level K serves as a

31
00:01:37,970 --> 00:01:45,890
cache holds a subset of the blocks of

32
00:01:42,430 --> 00:01:52,520
that are contained in the device at the

33
00:01:45,890 --> 00:01:54,950
lower level at level K plus-1 now recall

34
00:01:52,520 --> 00:01:58,880
the general idea of caching so we have a

35
00:01:54,950 --> 00:02:00,740
memory array of bytes and it's it's we

36
00:01:58,880 --> 00:02:05,899
break it up arbitrarily into a

37
00:02:00,740 --> 00:02:08,209
collection of blocks and these this

38
00:02:05,899 --> 00:02:12,140
memory is larger slower and cheaper and

39
00:02:08,209 --> 00:02:14,299
so it's and it's much larger than a

40
00:02:12,140 --> 00:02:17,180
cache which is smaller faster and more

41
00:02:14,299 --> 00:02:18,799
expensive and which holds and which

42
00:02:17,180 --> 00:02:22,850
holds a subset of the blocks that are

43
00:02:18,799 --> 00:02:24,769
contained in the main memory and then

44
00:02:22,850 --> 00:02:26,780
blocks are copied back and forth between

45
00:02:24,769 --> 00:02:29,660
the cache in the memory in these block

46
00:02:26,780 --> 00:02:33,200
size transfer units so for example if

47
00:02:29,660 --> 00:02:39,019
our program requests a word that's been

48
00:02:33,200 --> 00:02:41,600
contained in block number 4 it asks the

49
00:02:39,019 --> 00:02:44,150
cache to to sent to return the word

50
00:02:41,600 --> 00:02:46,489
that's contained in block 4 the cache

51
00:02:44,150 --> 00:02:48,140
looks and it's at the blocks that it's

52
00:02:46,489 --> 00:02:50,810
the subset of the blocks that it's

53
00:02:48,140 --> 00:02:53,480
towards discovers that block 4 is not

54
00:02:50,810 --> 00:02:57,350
there so it asks the main memory to send

55
00:02:53,480 --> 00:02:58,850
it block 4 which it does and I and then

56
00:02:57,350 --> 00:03:02,600
when it when that block arrives at the

57
00:02:58,850 --> 00:03:04,630
cache the cache stores if it potentially

58
00:03:02,600 --> 00:03:07,700
overwriting some existing block

59
00:03:04,630 --> 00:03:09,680
similarly if if our program asks for a

60
00:03:07,700 --> 00:03:13,070
data word if that's contained within

61
00:03:09,680 --> 00:03:15,500
block 10 the cache looks sees that it

62
00:03:13,070 --> 00:03:18,290
doesn't have that block so it requests

63
00:03:15,500 --> 00:03:19,819
that block from memory which copies it

64
00:03:18,290 --> 00:03:23,480
into the cache

65
00:03:19,819 --> 00:03:27,260
which overwrites an existing block now

66
00:03:23,480 --> 00:03:30,379
subsequently if if our program asks for

67
00:03:27,260 --> 00:03:32,689
a request or if our program references a

68
00:03:30,379 --> 00:03:35,989
word that's contained in block 10 for

69
00:03:32,689 --> 00:03:38,150
example then the cache then we have a

70
00:03:35,989 --> 00:03:40,879
hit and the cache can return that block

71
00:03:38,150 --> 00:03:43,159
immediately without going to the

72
00:03:40,879 --> 00:03:50,389
expensive operation of contacting memory

73
00:03:43,159 --> 00:03:51,950
and fetching that block from memory now

74
00:03:50,389 --> 00:03:54,290
there's a very important class of

75
00:03:51,950 --> 00:03:58,189
thought of caches these so called cache

76
00:03:54,290 --> 00:04:01,189
memories which are contained in the CPU

77
00:03:58,189 --> 00:04:03,319
chip itself and are managed completely

78
00:04:01,189 --> 00:04:08,150
by Hardware and they're implemented

79
00:04:03,319 --> 00:04:10,730
using fast SRAM memories and the idea

80
00:04:08,150 --> 00:04:14,599
for this cache which is is right next to

81
00:04:10,730 --> 00:04:17,090
the register file is to hold frequently

82
00:04:14,599 --> 00:04:19,190
access blocks or blocks from main memory

83
00:04:17,090 --> 00:04:21,590
that are accessed frequently okay so

84
00:04:19,190 --> 00:04:25,789
hopefully because of the principle of

85
00:04:21,590 --> 00:04:28,610
locality most of our requests for data

86
00:04:25,789 --> 00:04:31,940
will actually be served out of this

87
00:04:28,610 --> 00:04:34,340
cache memory in a few cycles rather than

88
00:04:31,940 --> 00:04:37,120
in this set rather than from this slow

89
00:04:34,340 --> 00:04:37,120
main memory

90
00:04:39,460 --> 00:04:45,169
now cache memories are managed

91
00:04:41,690 --> 00:04:47,750
completely in Hardware so this means

92
00:04:45,169 --> 00:04:50,150
that the heart there's there has to be

93
00:04:47,750 --> 00:04:53,150
Hardware logic that knows how to look

94
00:04:50,150 --> 00:04:54,740
for blocks in the cache and determine

95
00:04:53,150 --> 00:04:57,349
whether or not a particular block is

96
00:04:54,740 --> 00:04:59,539
contained there so cache memories are

97
00:04:57,349 --> 00:05:01,970
have to be organized in a very kind of

98
00:04:59,539 --> 00:05:04,849
strict simple way so that the logic the

99
00:05:01,970 --> 00:05:07,940
lookup logic can be pretty simple so

100
00:05:04,849 --> 00:05:12,050
this is very all cache memories are

101
00:05:07,940 --> 00:05:14,599
organized in the following way you can

102
00:05:12,050 --> 00:05:19,630
think of that you can think of the cache

103
00:05:14,599 --> 00:05:19,630
as an array of s equals to the s sets

104
00:05:19,919 --> 00:05:26,569
each set consists of e to the to e lines

105
00:05:27,770 --> 00:05:39,020
where each line consists of a block of D

106
00:05:33,300 --> 00:05:44,279
it equals 2 to the D bytes of data a

107
00:05:39,020 --> 00:05:46,710
valid bit which indicates whether these

108
00:05:44,279 --> 00:05:47,939
these data bits are actually the bits

109
00:05:46,710 --> 00:05:50,099
and the data block are actually

110
00:05:47,939 --> 00:05:52,110
meaningful right it's possible they

111
00:05:50,099 --> 00:05:53,509
could just be random bits like you know

112
00:05:52,110 --> 00:05:56,639
when you first turn on the machine

113
00:05:53,509 --> 00:05:58,650
there's nothing in the cache but those

114
00:05:56,639 --> 00:05:59,939
bits will have values right the ability

115
00:05:58,650 --> 00:06:02,370
to be ones or zeros but they won't

116
00:05:59,939 --> 00:06:05,400
actually correspond to data okay so the

117
00:06:02,370 --> 00:06:09,330
valid bit tells us if these if these be

118
00:06:05,400 --> 00:06:11,310
fights actually mean anything and then

119
00:06:09,330 --> 00:06:14,819
there's some additional bits called the

120
00:06:11,310 --> 00:06:16,490
tag bits which will help us search for

121
00:06:14,819 --> 00:06:19,219
blocks which I'll show you in a minute

122
00:06:16,490 --> 00:06:23,310
now when we talk about our cache size

123
00:06:19,219 --> 00:06:27,080
we're referring to the number of data

124
00:06:23,310 --> 00:06:32,939
bytes that are contained in blocks and

125
00:06:27,080 --> 00:06:37,770
so each cache has there's s sets there's

126
00:06:32,939 --> 00:06:40,560
e e blocks per set and there's B bytes

127
00:06:37,770 --> 00:06:46,259
per block okay so the total cache size C

128
00:06:40,560 --> 00:06:47,939
is s times e times B okay now so there's

129
00:06:46,259 --> 00:06:50,969
a lot of terms to sort of keep straight

130
00:06:47,939 --> 00:06:53,659
and it's very easy to get to confuse the

131
00:06:50,969 --> 00:06:56,819
difference between lines and blocks and

132
00:06:53,659 --> 00:06:59,490
lines and sets okay so we'll go through

133
00:06:56,819 --> 00:07:03,509
some examples and hopefully these will

134
00:06:59,490 --> 00:07:08,520
start to make more sense now let's look

135
00:07:03,509 --> 00:07:12,569
at in general how we how the cache

136
00:07:08,520 --> 00:07:15,599
Hardware implements a read so when our

137
00:07:12,569 --> 00:07:18,319
program accesses when our program

138
00:07:15,599 --> 00:07:23,339
executes some instruction that

139
00:07:18,319 --> 00:07:26,969
references some word in memory the the

140
00:07:23,339 --> 00:07:30,300
CPU sends that address to the cache and

141
00:07:26,969 --> 00:07:32,539
s and it asked the cache to return the

142
00:07:30,300 --> 00:07:32,539
word

143
00:07:32,660 --> 00:07:42,340
the word at that address and so the cash

144
00:07:37,550 --> 00:07:47,450
takes that address this would be a

145
00:07:42,340 --> 00:07:51,020
64-bit address in case of x86 64 and if

146
00:07:47,450 --> 00:07:53,900
it divides the address into a number of

147
00:07:51,020 --> 00:07:55,700
of regions which are which are

148
00:07:53,900 --> 00:07:58,340
determined by the organization of the

149
00:07:55,700 --> 00:08:03,440
cache okay they're determined by those

150
00:07:58,340 --> 00:08:05,780
parameters s that's the s the number of

151
00:08:03,440 --> 00:08:09,410
steps a the number of lines per set and

152
00:08:05,780 --> 00:08:12,500
B the size of each data block so the low

153
00:08:09,410 --> 00:08:15,530
order bits there are B low order bits

154
00:08:12,500 --> 00:08:22,390
which determine the offset in the block

155
00:08:15,530 --> 00:08:26,710
that that word starts at the next s bits

156
00:08:22,390 --> 00:08:29,660
are treated as an unsigned integer which

157
00:08:26,710 --> 00:08:31,910
serves as an index into the array of

158
00:08:29,660 --> 00:08:33,620
Seth can remember we just think of these

159
00:08:31,910 --> 00:08:38,500
as think of this cache as an array of

160
00:08:33,620 --> 00:08:41,360
set the set index bits provide the index

161
00:08:38,500 --> 00:08:46,430
into the into this array of sets and

162
00:08:41,360 --> 00:08:50,180
then all of the remaining bits all of

163
00:08:46,430 --> 00:08:52,610
the remaining T bits constitute what we

164
00:08:50,180 --> 00:08:56,120
call a tag which will help us when we do

165
00:08:52,610 --> 00:09:00,290
our search so the cache logic takes this

166
00:08:56,120 --> 00:09:03,800
address and it first extracts the the

167
00:09:00,290 --> 00:09:06,470
set index and uses that to as an index

168
00:09:03,800 --> 00:09:10,280
into this array to identify the set that

169
00:09:06,470 --> 00:09:13,310
if this block is in the set I'm sorry if

170
00:09:10,280 --> 00:09:17,180
the data word if the block that contains

171
00:09:13,310 --> 00:09:20,710
the data word at this address is in the

172
00:09:17,180 --> 00:09:26,220
cache it's going to be in the set

173
00:09:20,710 --> 00:09:29,800
denoted by the the set index okay

174
00:09:26,220 --> 00:09:32,190
so first it identifies which index to

175
00:09:29,800 --> 00:09:32,190
look in

176
00:09:35,330 --> 00:09:43,580
and then it checks the tag it checks all

177
00:09:40,160 --> 00:09:45,560
of the lines in that set to see if

178
00:09:43,580 --> 00:09:48,470
there's any any of those lines have a

179
00:09:45,560 --> 00:09:52,220
matching tag that a tag that matches the

180
00:09:48,470 --> 00:09:55,700
the T the tag bits in the address okay

181
00:09:52,220 --> 00:09:56,839
and if any checks to see if the valid

182
00:09:55,700 --> 00:09:58,370
bit is turned on so if those two

183
00:09:56,839 --> 00:10:01,459
conditions hold if there's a line

184
00:09:58,370 --> 00:10:04,279
anywhere in the set as of where the

185
00:10:01,459 --> 00:10:07,910
valid bit is is one and there's a

186
00:10:04,279 --> 00:10:09,560
matching tag then we have a hit okay

187
00:10:07,910 --> 00:10:17,120
then the block that we're looking for is

188
00:10:09,560 --> 00:10:19,190
contained in this set okay if we once we

189
00:10:17,120 --> 00:10:21,800
determine that with that we've we've

190
00:10:19,190 --> 00:10:24,769
identified the block then the cash uses

191
00:10:21,800 --> 00:10:27,230
that the low-order B bits to determine

192
00:10:24,769 --> 00:10:29,720
where that where the data we're

193
00:10:27,230 --> 00:10:33,920
interested in begins okay within that

194
00:10:29,720 --> 00:10:36,769
block all right let's look at a more

195
00:10:33,920 --> 00:10:39,740
specific example for a the simplest kind

196
00:10:36,769 --> 00:10:44,029
of cash which is when e equals one when

197
00:10:39,740 --> 00:10:47,120
there's only one line per set okay so a

198
00:10:44,029 --> 00:10:52,370
equal one one line per set this kind of

199
00:10:47,120 --> 00:10:55,010
cash is called a direct mapped cache so

200
00:10:52,370 --> 00:10:57,829
here we have a sets each set consists of

201
00:10:55,010 --> 00:11:00,740
a single line and now the pro suppose

202
00:10:57,829 --> 00:11:04,690
our program references the data item at

203
00:11:00,740 --> 00:11:07,820
a particular address the CPU sense that

204
00:11:04,690 --> 00:11:09,640
address to the cache the cache takes

205
00:11:07,820 --> 00:11:13,940
that address breaks it up into these

206
00:11:09,640 --> 00:11:14,959
into these three fields and then for

207
00:11:13,940 --> 00:11:20,360
this particular address

208
00:11:14,959 --> 00:11:22,820
the block offset is four and the set

209
00:11:20,360 --> 00:11:24,949
index is one and then there's some tag

210
00:11:22,820 --> 00:11:27,100
bits which we'll just denote with with

211
00:11:24,949 --> 00:11:31,300
the color pink

212
00:11:27,100 --> 00:11:34,339
so the cache extracts the set index

213
00:11:31,300 --> 00:11:38,260
which is one and then it uses that as as

214
00:11:34,339 --> 00:11:38,260
the index into the set

215
00:11:40,839 --> 00:11:46,310
and then it can just it just ignores all

216
00:11:43,730 --> 00:11:49,070
the other de set de block we're looking

217
00:11:46,310 --> 00:11:51,920
for is is in the cash it's going to be

218
00:11:49,070 --> 00:11:54,110
in this inset number one then it does

219
00:11:51,920 --> 00:11:56,540
the comparison of the tag dips and the

220
00:11:54,110 --> 00:11:59,260
valid bits and assume that they assume

221
00:11:56,540 --> 00:12:01,790
that valid bits on and that it matches

222
00:11:59,260 --> 00:12:07,670
then it looks at the block offset which

223
00:12:01,790 --> 00:12:09,500
is four and which tells it that the the

224
00:12:07,670 --> 00:12:11,630
four by four by ten suppose that that's

225
00:12:09,500 --> 00:12:14,570
what the instruction was was referencing

226
00:12:11,630 --> 00:12:18,050
the four byte in begins that offset for

227
00:12:14,570 --> 00:12:21,020
so now the cache takes take this int and

228
00:12:18,050 --> 00:12:29,570
it sent it back to the to the CPU which

229
00:12:21,020 --> 00:12:34,250
puts it in the register okay if the tag

230
00:12:29,570 --> 00:12:35,959
doesn't match then the old-line if the

231
00:12:34,250 --> 00:12:40,010
tag doesn't match then there's a miss

232
00:12:35,959 --> 00:12:42,709
and in that case the cache has to fetch

233
00:12:40,010 --> 00:12:46,250
the the block the corresponding blocks

234
00:12:42,709 --> 00:12:49,760
from memory and then overwrite this

235
00:12:46,250 --> 00:12:51,680
block in the line and then it can serve

236
00:12:49,760 --> 00:12:54,740
then it can fetch it can get the word

237
00:12:51,680 --> 00:12:58,580
out of out of the block and send it back

238
00:12:54,740 --> 00:13:00,470
to the processor you know let me ask you

239
00:12:58,580 --> 00:13:01,850
a question just to see if kind of check

240
00:13:00,470 --> 00:13:05,750
to see if you're following along with

241
00:13:01,850 --> 00:13:09,430
this so if there's a Miss and the cache

242
00:13:05,750 --> 00:13:11,900
has to request the block from memory

243
00:13:09,430 --> 00:13:16,730
fetch it from memory and then overwrite

244
00:13:11,900 --> 00:13:21,170
the block in the current line does it

245
00:13:16,730 --> 00:13:23,510
also have to change the tag dips or two

246
00:13:21,170 --> 00:13:26,870
those stay the same so does the do the

247
00:13:23,510 --> 00:13:30,290
tag bits that were in this line get

248
00:13:26,870 --> 00:13:32,600
overwritten with a different value or is

249
00:13:30,290 --> 00:13:43,910
it the same

250
00:13:32,600 --> 00:13:46,540
same different save different now why

251
00:13:43,910 --> 00:13:46,540
would it be different

252
00:13:47,630 --> 00:13:57,529
we haven't changed yes I'm sorry

253
00:13:58,730 --> 00:14:03,750
Olek it almost certainly has different

254
00:14:01,949 --> 00:14:16,139
data but does it have a different

255
00:14:03,750 --> 00:14:18,930
address exactly it missed it missed

256
00:14:16,139 --> 00:14:21,500
because the tag it missed because the

257
00:14:18,930 --> 00:14:24,720
tag didn't match

258
00:14:21,500 --> 00:14:26,550
if the valid bit was false and the tag

259
00:14:24,720 --> 00:14:30,449
match then then that would also be a

260
00:14:26,550 --> 00:14:33,720
miss oh then you wouldn't okay that's

261
00:14:30,449 --> 00:14:41,910
right that's okay good good good okay

262
00:14:33,720 --> 00:14:45,120
great all right let me do a little let

263
00:14:41,910 --> 00:14:49,199
me do a really simple specific example

264
00:14:45,120 --> 00:14:52,680
of how a direct mapped cache works III

265
00:14:49,199 --> 00:14:54,240
want you to understand in real detail

266
00:14:52,680 --> 00:14:57,480
how this would work but I also want to

267
00:14:54,240 --> 00:15:00,269
make a point for about the weakness of

268
00:14:57,480 --> 00:15:01,709
direct mapped cache --is and why why you

269
00:15:00,269 --> 00:15:06,449
would want to have more than one line

270
00:15:01,709 --> 00:15:08,880
per set okay so we this is a really

271
00:15:06,449 --> 00:15:12,180
simple our met we have our memory system

272
00:15:08,880 --> 00:15:15,149
consists of 16 bytes okay so it's not a

273
00:15:12,180 --> 00:15:19,410
very useful system with 4-bit addresses

274
00:15:15,149 --> 00:15:24,050
and and it's broken up into blocks of 2

275
00:15:19,410 --> 00:15:27,470
bytes each our cache consists of 4 sets

276
00:15:24,050 --> 00:15:33,149
with one block per set

277
00:15:27,470 --> 00:15:36,839
now our 4 by our 4-bit addresses because

278
00:15:33,149 --> 00:15:39,180
be equal to that's 2 to the 1 we only

279
00:15:36,839 --> 00:15:42,720
need one block offset bit right there's

280
00:15:39,180 --> 00:15:44,399
only 2 bytes in a block so the byte

281
00:15:42,720 --> 00:15:49,560
we're looking for is either at 0 or 1

282
00:15:44,399 --> 00:15:52,920
okay because we have 4 sets we need to

283
00:15:49,560 --> 00:15:55,470
set off set index bits and then the

284
00:15:52,920 --> 00:15:58,709
remaining bits are always tag bits in

285
00:15:55,470 --> 00:15:59,880
this case there's just one tag dead all

286
00:15:58,709 --> 00:16:04,470
right now let's

287
00:15:59,880 --> 00:16:07,670
let's suppose that our program executes

288
00:16:04,470 --> 00:16:10,529
instructions that reference the

289
00:16:07,670 --> 00:16:14,430
following memory addresses zero one

290
00:16:10,529 --> 00:16:16,680
seven eight and zero and these

291
00:16:14,430 --> 00:16:19,230
references are reads that they're

292
00:16:16,680 --> 00:16:23,579
reading one byte per read okay like I

293
00:16:19,230 --> 00:16:25,259
said this is a really simple system so

294
00:16:23,579 --> 00:16:28,709
let's look at what happens now we start

295
00:16:25,259 --> 00:16:35,810
out Arte are initially are our cache is

296
00:16:28,709 --> 00:16:38,579
empty valid bits are all set to zero and

297
00:16:35,810 --> 00:16:43,230
now the cache receives the request for

298
00:16:38,579 --> 00:16:45,449
the byte that's at address zero so it

299
00:16:43,230 --> 00:16:49,500
extracts the set index bits which in

300
00:16:45,449 --> 00:16:54,630
this case are zero zero so these so it's

301
00:16:49,500 --> 00:16:56,490
going to look in set zero four and in

302
00:16:54,630 --> 00:17:00,660
this case since valid is zero it's just

303
00:16:56,490 --> 00:17:06,059
it's a Miss okay so it's etches that

304
00:17:00,660 --> 00:17:10,020
block from memory sticks the block so

305
00:17:06,059 --> 00:17:11,789
this memory this is the decent this is

306
00:17:10,020 --> 00:17:15,319
using array notation for memory so this

307
00:17:11,789 --> 00:17:18,150
is like the the byte that extend from

308
00:17:15,319 --> 00:17:24,750
offset zero to offset one inclusive in

309
00:17:18,150 --> 00:17:27,480
memory the tag bit is zero and the valid

310
00:17:24,750 --> 00:17:31,940
bit is 1 ok now the next the next

311
00:17:27,480 --> 00:17:34,590
address that comes by is for address 1

312
00:17:31,940 --> 00:17:38,070
well that's a hit right because we set

313
00:17:34,590 --> 00:17:40,940
block the block that contains the byte

314
00:17:38,070 --> 00:17:44,700
and address 1 is already in the cache

315
00:17:40,940 --> 00:17:47,880
the tag and the tags match okay so we're

316
00:17:44,700 --> 00:17:53,429
good that's a hit you now we get address

317
00:17:47,880 --> 00:17:56,280
7 so the cache extracts the set index

318
00:17:53,429 --> 00:18:01,830
bits which in this case are 1 1 or 4 or

319
00:17:56,280 --> 00:18:05,190
3 rather looks in set 3 there's no valid

320
00:18:01,830 --> 00:18:09,480
bit so that's a Miss and it loads the

321
00:18:05,190 --> 00:18:11,910
data for memory that spans

322
00:18:09,480 --> 00:18:16,030
bytes 6 & 7

323
00:18:11,910 --> 00:18:19,960
and in this case the the tag that is

324
00:18:16,030 --> 00:18:21,870
zero okay so we record that we record

325
00:18:19,960 --> 00:18:24,280
that in our metadata

326
00:18:21,870 --> 00:18:29,740
okay the next reference that comes by is

327
00:18:24,280 --> 00:18:34,620
8 now 8 has a set index of zero zero

328
00:18:29,740 --> 00:18:37,780
zero but that's currently occupied by

329
00:18:34,620 --> 00:18:42,700
block zero one and we can tell that

330
00:18:37,780 --> 00:18:45,820
because address 8 has a tag of 1 and the

331
00:18:42,700 --> 00:18:48,430
existing block of the block at the

332
00:18:45,820 --> 00:18:51,700
earlier address at address 0 has a tag

333
00:18:48,430 --> 00:18:56,200
of zero so that's a Miss so now we have

334
00:18:51,700 --> 00:18:59,370
to go fetch the block containing byte

335
00:18:56,200 --> 00:19:04,890
number 8 into memory so now we have

336
00:18:59,370 --> 00:19:10,210
bytes 8 & 9 and we in our new tag did

337
00:19:04,890 --> 00:19:15,070
okay now the next instruction is for

338
00:19:10,210 --> 00:19:17,110
byte 0 and we just we just replace we

339
00:19:15,070 --> 00:19:20,440
had that it we had that in our cache and

340
00:19:17,110 --> 00:19:24,250
we just replaced it so so it's another

341
00:19:20,440 --> 00:19:26,770
miss so that's unfortunate and it's the

342
00:19:24,250 --> 00:19:31,390
only reason we missed it is because

343
00:19:26,770 --> 00:19:38,350
we've got just one line per set and so

344
00:19:31,390 --> 00:19:41,010
we were forced to overwrite that that

345
00:19:38,350 --> 00:19:47,040
block containing bytes the block 0 1

346
00:19:41,010 --> 00:19:50,170
when we when we missed on on block 8 9

347
00:19:47,040 --> 00:19:51,700
okay so this and you see there's plenty

348
00:19:50,170 --> 00:19:55,150
of room in our cache we've still got

349
00:19:51,700 --> 00:19:57,970
we've got two two lines that we haven't

350
00:19:55,150 --> 00:20:01,390
even access right so we our cache is

351
00:19:57,970 --> 00:20:04,180
plenty big but just because of the sort

352
00:20:01,390 --> 00:20:07,300
of the low associativity of our cache

353
00:20:04,180 --> 00:20:08,670
and the sort of the pattern the access

354
00:20:07,300 --> 00:20:11,710
patterns that we were presented with

355
00:20:08,670 --> 00:20:16,680
we've got a miss that really was kind of

356
00:20:11,710 --> 00:20:16,680
unnecessary so oh yeah sorry

357
00:20:28,360 --> 00:20:36,190
six so when we referenced when we

358
00:20:32,179 --> 00:20:40,130
referenced a seven it's actually the

359
00:20:36,190 --> 00:20:42,679
it's at offset one in that block six

360
00:20:40,130 --> 00:20:44,750
seven okay since our blocks are two

361
00:20:42,679 --> 00:20:47,169
bytes they'll always start on an even

362
00:20:44,750 --> 00:20:47,169
multiple

363
00:20:51,210 --> 00:21:02,759
any other questions okay so this so this

364
00:21:00,059 --> 00:21:05,849
sort of is the reason why you have

365
00:21:02,759 --> 00:21:10,440
caches have higher associativity higher

366
00:21:05,849 --> 00:21:15,629
values of e so let's look at and so for

367
00:21:10,440 --> 00:21:20,369
for values of e greater for values of e

368
00:21:15,629 --> 00:21:21,809
greater than greater than one we refer

369
00:21:20,369 --> 00:21:25,499
to them as a way associate set

370
00:21:21,809 --> 00:21:29,479
associative caches so here e equals two

371
00:21:25,499 --> 00:21:33,029
so it's a 2-way it's 2-way associative

372
00:21:29,479 --> 00:21:36,479
so let's let's suppose we have a a 2-way

373
00:21:33,029 --> 00:21:39,629
a 2-way associative cache so here we

374
00:21:36,479 --> 00:21:43,049
have we have our array of sets and now

375
00:21:39,629 --> 00:21:48,839
each set contains two lines okay instead

376
00:21:43,049 --> 00:21:52,609
of one line and suppose we're presented

377
00:21:48,839 --> 00:21:55,109
with an address with the following form

378
00:21:52,609 --> 00:21:59,779
we're looking for the word that begins

379
00:21:55,109 --> 00:22:08,489
at an off set of four inside our block

380
00:21:59,779 --> 00:22:12,479
at within set number one okay so the

381
00:22:08,489 --> 00:22:18,019
cache extracts that set index so this is

382
00:22:12,479 --> 00:22:21,809
set 0 this is set 1 this is set to

383
00:22:18,019 --> 00:22:28,320
throws away all the other sets and now

384
00:22:21,809 --> 00:22:31,200
in parallel it searches it searches the

385
00:22:28,320 --> 00:22:34,879
tags it searches for a matching tag in

386
00:22:31,200 --> 00:22:37,409
both of these both of these lines and

387
00:22:34,879 --> 00:22:41,580
anti valid bits so if we get a matching

388
00:22:37,409 --> 00:22:48,229
tag and a valid bit true then we've got

389
00:22:41,580 --> 00:22:51,229
a a then we've got a hit now that yep

390
00:22:48,229 --> 00:22:51,229
yep

391
00:22:54,010 --> 00:23:00,790
oh it's a very good question so there's

392
00:22:58,450 --> 00:23:04,090
this hardware logic that does that

393
00:23:00,790 --> 00:23:06,670
compare and it's and that's the reason

394
00:23:04,090 --> 00:23:08,710
that as as the number of as the

395
00:23:06,670 --> 00:23:11,170
associativity goes up that logic gets

396
00:23:08,710 --> 00:23:13,750
more and more expensive okay it's like

397
00:23:11,170 --> 00:23:18,220
some like you're kind of doing some kind

398
00:23:13,750 --> 00:23:20,080
of tree search and so that actually is

399
00:23:18,220 --> 00:23:22,930
the limit that's why I mean because in

400
00:23:20,080 --> 00:23:27,450
general right that if you take this to

401
00:23:22,930 --> 00:23:30,010
the limit there's just one set with

402
00:23:27,450 --> 00:23:31,690
there's just it's we call that a fully

403
00:23:30,010 --> 00:23:35,020
associative cache so there's just one

404
00:23:31,690 --> 00:23:37,150
set and now any block a block can go

405
00:23:35,020 --> 00:23:39,940
anywhere right there's no constraints

406
00:23:37,150 --> 00:23:42,970
now where you place a block but the

407
00:23:39,940 --> 00:23:46,180
because of the complexity of that that

408
00:23:42,970 --> 00:23:50,380
fully associative search those are very

409
00:23:46,180 --> 00:23:52,270
rare in fact you do see will see fully

410
00:23:50,380 --> 00:23:56,290
associative caches caches but their

411
00:23:52,270 --> 00:24:00,690
software caches okay so in software and

412
00:23:56,290 --> 00:24:06,490
so the the complexity the hardware and

413
00:24:00,690 --> 00:24:08,560
sort of doesn't doesn't doesn't it's not

414
00:24:06,490 --> 00:24:10,750
worth it's not worth the complexity of

415
00:24:08,560 --> 00:24:13,270
the hardware for the penalty of having a

416
00:24:10,750 --> 00:24:15,220
lower associative 'ti okay but there are

417
00:24:13,270 --> 00:24:19,060
some systems later on when we study

418
00:24:15,220 --> 00:24:22,330
virtual memory the in a virtual memory

419
00:24:19,060 --> 00:24:25,390
system the DRAM serves as a cache for

420
00:24:22,330 --> 00:24:28,930
data stored on the disk and as we saw

421
00:24:25,390 --> 00:24:31,030
last time the penalty for a miss if you

422
00:24:28,930 --> 00:24:33,550
have a cache on DRAM and you miss and

423
00:24:31,030 --> 00:24:35,920
you have to go to disk the penalty is

424
00:24:33,550 --> 00:24:38,170
huge for that and so because of that

425
00:24:35,920 --> 00:24:42,640
it's worth it's worthwhile having very

426
00:24:38,170 --> 00:24:45,670
complex searches search algorithms in

427
00:24:42,640 --> 00:24:48,310
particular in a virtual memory system

428
00:24:45,670 --> 00:24:50,230
that the DRAM is implements a fully

429
00:24:48,310 --> 00:24:52,060
associative cache where blocks from disk

430
00:24:50,230 --> 00:24:54,670
can go anywhere we'll get into that

431
00:24:52,060 --> 00:24:55,990
later when we look in virtual memory but

432
00:24:54,670 --> 00:24:58,570
you're right you'll see in real systems

433
00:24:55,990 --> 00:25:00,960
nowadays that the number goes up right

434
00:24:58,570 --> 00:25:03,270
because feature sizes are going down and

435
00:25:00,960 --> 00:25:06,970
designers can afford to implement more

436
00:25:03,270 --> 00:25:07,309
expensive hardware but the the largest

437
00:25:06,970 --> 00:25:09,350
of

438
00:25:07,309 --> 00:25:12,830
tivity on Intel systems that I know of

439
00:25:09,350 --> 00:25:14,330
is 16-way associative l3 caches and then

440
00:25:12,830 --> 00:25:15,230
the others are 8 way associative so

441
00:25:14,330 --> 00:25:20,990
that's sort of the order of magnitude

442
00:25:15,230 --> 00:25:23,720
that's state of the art right now ok so

443
00:25:20,990 --> 00:25:26,929
then once we've identified a match we

444
00:25:23,720 --> 00:25:30,409
use the set offset bits in this case

445
00:25:26,929 --> 00:25:34,490
we're accessing a short int so 4 is the

446
00:25:30,409 --> 00:25:36,499
offset within the block of this the 2

447
00:25:34,490 --> 00:25:39,980
byte short int which then we can return

448
00:25:36,499 --> 00:25:41,690
to the processor alright so let's do

449
00:25:39,980 --> 00:25:45,529
that same simulation that we did before

450
00:25:41,690 --> 00:25:50,720
but this time with a 2-way associative

451
00:25:45,529 --> 00:25:52,789
cache now memory system is the same but

452
00:25:50,720 --> 00:25:57,440
now instead of one set we have two sets

453
00:25:52,789 --> 00:26:00,470
and I mean I'm sorry instead of four

454
00:25:57,440 --> 00:26:02,389
sets we have two sets so the cache this

455
00:26:00,470 --> 00:26:04,669
is the same sized cache but we're just

456
00:26:02,389 --> 00:26:06,409
going to organize it differently instead

457
00:26:04,669 --> 00:26:10,549
of one way instead of a direct mapped

458
00:26:06,409 --> 00:26:12,740
cache with four lines containing four

459
00:26:10,549 --> 00:26:15,259
lines one line per set we're going to

460
00:26:12,740 --> 00:26:17,690
implement a 2-way associative cache

461
00:26:15,259 --> 00:26:20,330
where we have two sets with two lines

462
00:26:17,690 --> 00:26:24,730
per set okay so each case is just four

463
00:26:20,330 --> 00:26:24,730
there's four total lines question

464
00:26:26,870 --> 00:26:33,290
and it was like oh so that that comes in

465
00:26:30,920 --> 00:26:36,850
with the request somehow and I actually

466
00:26:33,290 --> 00:26:39,460
don't know the details of that it may I

467
00:26:36,850 --> 00:26:41,630
guess there so it could ask for just

468
00:26:39,460 --> 00:26:45,950
there could just be a default sighs

469
00:26:41,630 --> 00:26:47,990
maybe it's always it's always a 64 by

470
00:26:45,950 --> 00:26:50,330
word and then the processor extracts

471
00:26:47,990 --> 00:26:53,030
that the current bits I actually don't

472
00:26:50,330 --> 00:26:55,190
know the details of that but it either

473
00:26:53,030 --> 00:26:56,990
comes in on the request or or there's a

474
00:26:55,190 --> 00:27:01,610
standard there's a standard size that

475
00:26:56,990 --> 00:27:03,410
the processor then parses out we'll just

476
00:27:01,610 --> 00:27:09,350
assume that the cache knows the wood

477
00:27:03,410 --> 00:27:11,210
size to return yes how do you decide

478
00:27:09,350 --> 00:27:12,650
which block to your place that's that's

479
00:27:11,210 --> 00:27:15,290
a really good question so there's a lot

480
00:27:12,650 --> 00:27:17,690
of different algorithms the most the

481
00:27:15,290 --> 00:27:21,140
most common algorithm or a common

482
00:27:17,690 --> 00:27:23,840
algorithm is least recently used so by

483
00:27:21,140 --> 00:27:25,340
locality you want to keep the you want

484
00:27:23,840 --> 00:27:28,670
to keep blocks in the cache that are

485
00:27:25,340 --> 00:27:30,530
being used a lot and so if a block isn't

486
00:27:28,670 --> 00:27:32,690
referenced for a long time by the

487
00:27:30,530 --> 00:27:36,320
principle of locality by sort of the

488
00:27:32,690 --> 00:27:38,630
inverse locality principle it's likely

489
00:27:36,320 --> 00:27:42,080
not to be addressed referenced in the

490
00:27:38,630 --> 00:27:45,020
near future so so that's one that's one

491
00:27:42,080 --> 00:27:47,690
algorithm that you just keep track of

492
00:27:45,020 --> 00:27:49,820
and and I'm not showing that there needs

493
00:27:47,690 --> 00:27:52,250
to be additional bits in the line to

494
00:27:49,820 --> 00:27:55,130
sort of keep like sort of virtual

495
00:27:52,250 --> 00:27:56,840
timestamps that but that's that's a

496
00:27:55,130 --> 00:27:59,750
that's sort of the general way you do it

497
00:27:56,840 --> 00:28:02,150
just try to keep the things that are the

498
00:27:59,750 --> 00:28:06,550
blocks that are being accessed the most

499
00:28:02,150 --> 00:28:06,550
frequently the most recently yes

500
00:28:08,010 --> 00:28:13,630
okay the question is what determines the

501
00:28:10,780 --> 00:28:16,300
block size that's determined by the

502
00:28:13,630 --> 00:28:19,480
design of the memory system so that's a

503
00:28:16,300 --> 00:28:21,790
that's that's a sixth parameter of the

504
00:28:19,480 --> 00:28:25,180
memory system so when the Intel

505
00:28:21,790 --> 00:28:27,880
designers decided to put cache memories

506
00:28:25,180 --> 00:28:36,720
on their processors they decided that

507
00:28:27,880 --> 00:28:36,720
the block size would be 64 bytes sorry

508
00:28:38,280 --> 00:28:46,660
so the block size comes the block size

509
00:28:42,640 --> 00:28:50,080
comes first then then you determine how

510
00:28:46,660 --> 00:28:53,490
big you want your cache to be okay and

511
00:28:50,080 --> 00:28:56,320
then and you determine the associativity

512
00:28:53,490 --> 00:28:58,240
okay and then once you determine the

513
00:28:56,320 --> 00:29:00,460
associativity and you know how big your

514
00:28:58,240 --> 00:29:01,990
cache is then that determines the number

515
00:29:00,460 --> 00:29:13,150
of sets okay

516
00:29:01,990 --> 00:29:15,730
so basically all of those the the the

517
00:29:13,150 --> 00:29:18,130
number of lines and the cat and the

518
00:29:15,730 --> 00:29:20,230
capacity the number of lines per set is

519
00:29:18,130 --> 00:29:22,690
sort of a sixth high level parameter

520
00:29:20,230 --> 00:29:26,170
design parameter the size of the cache

521
00:29:22,690 --> 00:29:28,210
is a is a high level design parameter

522
00:29:26,170 --> 00:29:32,970
and then the number of sets then is

523
00:29:28,210 --> 00:29:32,970
induced from from that okay yes

524
00:29:40,300 --> 00:29:46,400
that's that's yeah how does so that's

525
00:29:43,070 --> 00:29:47,870
that's the replacement policy how does

526
00:29:46,400 --> 00:29:49,340
it so question is how does it when

527
00:29:47,870 --> 00:29:51,320
there's multiple lines in a set how does

528
00:29:49,340 --> 00:29:53,420
it determine which to over-over right

529
00:29:51,320 --> 00:29:55,070
and that was what that was the previous

530
00:29:53,420 --> 00:29:57,680
question probably maybe I should have

531
00:29:55,070 --> 00:30:00,890
repeated it so you try to pick a line

532
00:29:57,680 --> 00:30:03,700
that that was least recently used so

533
00:30:00,890 --> 00:30:05,660
lines lines that haven't been accessed

534
00:30:03,700 --> 00:30:07,730
recently are good candidates for

535
00:30:05,660 --> 00:30:09,710
replacement because because of the sort

536
00:30:07,730 --> 00:30:12,230
of inverse locality principle right that

537
00:30:09,710 --> 00:30:13,880
they haven't been inversed referenced

538
00:30:12,230 --> 00:30:19,460
recently chances are they won't be

539
00:30:13,880 --> 00:30:20,750
referenced again it oh yeah there's

540
00:30:19,460 --> 00:30:23,540
additional bits that I'm not showing

541
00:30:20,750 --> 00:30:26,600
here that you have to so so when you

542
00:30:23,540 --> 00:30:28,610
replace a line in the set if that data

543
00:30:26,600 --> 00:30:31,220
has changed then it has to be written

544
00:30:28,610 --> 00:30:47,120
back to memory and that's another good I

545
00:30:31,220 --> 00:30:50,620
haven't shown yes ah so the so yeah so

546
00:30:47,120 --> 00:30:52,970
this is a really this is really tricky

547
00:30:50,620 --> 00:30:55,790
parameter right it's a it's a high level

548
00:30:52,970 --> 00:30:56,560
system parameter that's that it goes on

549
00:30:55,790 --> 00:30:59,570
for years

550
00:30:56,560 --> 00:31:03,170
so the idea you want to have blocks in

551
00:30:59,570 --> 00:31:04,400
order to exploit spatial locality right

552
00:31:03,170 --> 00:31:06,830
think about if you're going to go to the

553
00:31:04,400 --> 00:31:09,170
trouble of if you have a Miss in cache

554
00:31:06,830 --> 00:31:11,330
and you're going to go to the trouble of

555
00:31:09,170 --> 00:31:14,360
going all the way to memory to get some

556
00:31:11,330 --> 00:31:17,120
data you want to you want to amortize

557
00:31:14,360 --> 00:31:19,820
the cost of fetching that data by

558
00:31:17,120 --> 00:31:22,670
fetching more than one byte that's

559
00:31:19,820 --> 00:31:25,460
that's the motivation for blocks because

560
00:31:22,670 --> 00:31:30,830
by by the by the principle of locality

561
00:31:25,460 --> 00:31:32,510
in spatial locality in particular if you

562
00:31:30,830 --> 00:31:34,100
reference a word inside of a block

563
00:31:32,510 --> 00:31:35,930
chances are you're going to reference a

564
00:31:34,100 --> 00:31:36,590
nearby word which will also be an

565
00:31:35,930 --> 00:31:39,290
epilogue

566
00:31:36,590 --> 00:31:42,430
okay so blocks the whole purpose of

567
00:31:39,290 --> 00:31:46,899
blocks is to exploit spatial locality

568
00:31:42,430 --> 00:31:49,629
now if you make your block too small

569
00:31:46,899 --> 00:31:51,219
then you don't you don't amortize you

570
00:31:49,629 --> 00:31:53,999
don't get the same amortization right

571
00:31:51,219 --> 00:31:56,259
you maybe get one you bring the block in

572
00:31:53,999 --> 00:31:58,389
so there's a reference you get a mist

573
00:31:56,259 --> 00:32:00,129
you bring the block in there's another

574
00:31:58,389 --> 00:32:02,739
reference nearby you get a hit because

575
00:32:00,129 --> 00:32:04,509
the blocks are memory but then the next

576
00:32:02,739 --> 00:32:06,519
reference is in a different block

577
00:32:04,509 --> 00:32:09,879
because your block sizes are too small

578
00:32:06,519 --> 00:32:12,729
so you kind of want to make blocks big

579
00:32:09,879 --> 00:32:14,229
as big as possible but without slowing

580
00:32:12,729 --> 00:32:15,879
the system down so if you made your

581
00:32:14,229 --> 00:32:20,639
block size too big it would just take

582
00:32:15,879 --> 00:32:23,589
too long to bring that block in plus

583
00:32:20,639 --> 00:32:26,409
plus now your block that your blocks are

584
00:32:23,589 --> 00:32:27,909
taking up bits in your cache memory so

585
00:32:26,409 --> 00:32:29,739
now there's no room for other blocks

586
00:32:27,909 --> 00:32:33,129
right so it's a really it's a really

587
00:32:29,739 --> 00:32:35,109
tricky design problem right and I if

588
00:32:33,129 --> 00:32:36,580
we're doing it's taking an architecture

589
00:32:35,109 --> 00:32:39,309
class then we would we would sort of

590
00:32:36,580 --> 00:32:41,169
dive into the you know how how

591
00:32:39,309 --> 00:32:43,419
architects make those design decisions

592
00:32:41,169 --> 00:32:46,659
but in general that's what it's kind of

593
00:32:43,419 --> 00:32:49,739
a balancing act right there any other

594
00:32:46,659 --> 00:32:49,739
questions yes

595
00:32:52,880 --> 00:32:54,910
Oh

596
00:32:56,630 --> 00:32:59,960
the question is every time there's a

597
00:32:58,220 --> 00:33:02,620
myth do you have to do you have to

598
00:32:59,960 --> 00:33:05,320
select a victim line and overwrite it

599
00:33:02,620 --> 00:33:08,630
yeah I don't know of any caches that

600
00:33:05,320 --> 00:33:11,270
that don't do that now we'll see when we

601
00:33:08,630 --> 00:33:13,790
look at writes we'll see there's an

602
00:33:11,270 --> 00:33:15,920
option of whether we're only looking at

603
00:33:13,790 --> 00:33:19,730
reads right now but with writes that

604
00:33:15,920 --> 00:33:22,700
question does come up and if if you

605
00:33:19,730 --> 00:33:23,120
waited in a couple of slides we'll go

606
00:33:22,700 --> 00:33:27,400
over

607
00:33:23,120 --> 00:33:27,400
we'll go over that any other questions

608
00:33:28,180 --> 00:33:34,400
okay so let's look at this this two-way

609
00:33:31,010 --> 00:33:37,820
associative cache now there's there's

610
00:33:34,400 --> 00:33:39,860
one block offset bit we only have two

611
00:33:37,820 --> 00:33:42,230
sets so that we only need one set index

612
00:33:39,860 --> 00:33:45,530
and then the remaining two bits are

613
00:33:42,230 --> 00:33:48,890
tagged so let's go through our trace so

614
00:33:45,530 --> 00:33:53,390
address zero has a set is in set zero

615
00:33:48,890 --> 00:34:00,290
right here that's a Miss so we load that

616
00:33:53,390 --> 00:34:03,440
into memory with the reference to

617
00:34:00,290 --> 00:34:06,020
address one that's in set zero and

618
00:34:03,440 --> 00:34:09,560
that's a hit because that that byte is

619
00:34:06,020 --> 00:34:12,290
in is in our block the reference to

620
00:34:09,560 --> 00:34:14,030
seven is a Miss that's in set one so we

621
00:34:12,290 --> 00:34:16,910
load that and we were just picking

622
00:34:14,030 --> 00:34:20,560
randomly tick one of these two over

623
00:34:16,910 --> 00:34:23,180
right because they're the cache is empty

624
00:34:20,560 --> 00:34:26,390
the next reference is to address number

625
00:34:23,180 --> 00:34:28,700
eight which is in set zero now here's

626
00:34:26,390 --> 00:34:30,680
here's the difference between the direct

627
00:34:28,700 --> 00:34:33,500
mapped cache and this too late set

628
00:34:30,680 --> 00:34:38,480
associative cache when we when we

629
00:34:33,500 --> 00:34:40,430
reference address eight that block has

630
00:34:38,480 --> 00:34:44,450
to the corresponding block has to go

631
00:34:40,430 --> 00:34:46,730
into set 0 because of this 0 set index

632
00:34:44,450 --> 00:34:48,260
bit but we've got room now because we

633
00:34:46,730 --> 00:34:51,800
are set to have room for two lines

634
00:34:48,260 --> 00:34:54,920
instead of one so when we load that in

635
00:34:51,800 --> 00:34:56,270
well if we have an available empty slot

636
00:34:54,920 --> 00:34:58,130
we'll put it there we won't overwrite

637
00:34:56,270 --> 00:35:01,930
anything right so if possible always try

638
00:34:58,130 --> 00:35:04,620
to overwrite empty empty lines

639
00:35:01,930 --> 00:35:08,740
so now we've got in this set we've got

640
00:35:04,620 --> 00:35:12,180
block 0 1 and block 8 9 so when we get

641
00:35:08,740 --> 00:35:15,010
our reference to block to address 0

642
00:35:12,180 --> 00:35:16,540
whereas before with the when we had a

643
00:35:15,010 --> 00:35:19,300
conflict miss in the direct mapped cache

644
00:35:16,540 --> 00:35:21,730
now we can we can satisfy that that

645
00:35:19,300 --> 00:35:23,920
request it hits in memory and we can the

646
00:35:21,730 --> 00:35:29,470
cache can satisfy it from from the cache

647
00:35:23,920 --> 00:35:39,130
instead of going to memory ok so that

648
00:35:29,470 --> 00:35:41,130
makes sense ok now what about writes so

649
00:35:39,130 --> 00:35:44,080
there's multiple copies of the data

650
00:35:41,130 --> 00:35:46,810
right we're subsetting as we move up the

651
00:35:44,080 --> 00:35:52,750
hierarchy we're creating subsets of the

652
00:35:46,810 --> 00:35:58,510
data in the caches so what do we do if

653
00:35:52,750 --> 00:36:03,160
we do a write to a word within a block

654
00:35:58,510 --> 00:36:06,070
that's currently in the cache ok we have

655
00:36:03,160 --> 00:36:08,730
we have two options we can write that

656
00:36:06,070 --> 00:36:11,140
block immediately to memory right we're

657
00:36:08,730 --> 00:36:14,070
we've got a block that's like this big

658
00:36:11,140 --> 00:36:16,990
and we're updating a little chunk of it

659
00:36:14,070 --> 00:36:18,670
so we can we can either do the update

660
00:36:16,990 --> 00:36:21,820
and then flush it to memory immediately

661
00:36:18,670 --> 00:36:23,680
so that memory always mirrors the

662
00:36:21,820 --> 00:36:28,510
contents of memory always mirror the

663
00:36:23,680 --> 00:36:30,970
contents of the cache ok but that's

664
00:36:28,510 --> 00:36:34,390
expensive right I mean you know memory

665
00:36:30,970 --> 00:36:36,190
accesses are expensive the other so the

666
00:36:34,390 --> 00:36:36,820
other option is what what's called write

667
00:36:36,190 --> 00:36:39,580
back

668
00:36:36,820 --> 00:36:43,810
so in this case when we write to a block

669
00:36:39,580 --> 00:36:47,620
in the cache we don't we don't flush it

670
00:36:43,810 --> 00:36:50,050
to memory until we elect that particular

671
00:36:47,620 --> 00:36:53,950
line as a victim that's going to be

672
00:36:50,050 --> 00:36:56,260
overwritten and only then only then when

673
00:36:53,950 --> 00:36:58,230
we're just we sort of defer the writing

674
00:36:56,260 --> 00:37:02,200
to memory until the last possible minute

675
00:36:58,230 --> 00:37:05,380
we defer it until just before the cache

676
00:37:02,200 --> 00:37:07,510
would overwrite that that data block ok

677
00:37:05,380 --> 00:37:08,950
so that's called write back and for

678
00:37:07,510 --> 00:37:10,270
write back you need to have some an

679
00:37:08,950 --> 00:37:12,940
extra bit in the line that indicates

680
00:37:10,270 --> 00:37:15,880
whether that that blocks been written to

681
00:37:12,940 --> 00:37:17,920
so the algorithm is when when the cash

682
00:37:15,880 --> 00:37:21,130
identifies the particular line to

683
00:37:17,920 --> 00:37:23,620
overwrite it checks the dirty bit on

684
00:37:21,130 --> 00:37:29,140
that line if it's set then it writes

685
00:37:23,620 --> 00:37:30,850
that data to back to disk if the if the

686
00:37:29,140 --> 00:37:32,260
data hasn't if that block has a good

687
00:37:30,850 --> 00:37:34,300
written there's no point there's no need

688
00:37:32,260 --> 00:37:37,330
to write it back because it's the same

689
00:37:34,300 --> 00:37:43,180
it has the same value as the copy of the

690
00:37:37,330 --> 00:37:44,740
block on disk ok now so what about so

691
00:37:43,180 --> 00:37:46,990
that's a right here now what happens if

692
00:37:44,740 --> 00:37:51,640
we have a right missed so we're doing a

693
00:37:46,990 --> 00:37:54,760
right to memory and the word that we're

694
00:37:51,640 --> 00:37:58,300
writing is is not contained in any block

695
00:37:54,760 --> 00:37:59,800
that's in our cache so we have two

696
00:37:58,300 --> 00:38:01,690
options we can do what's called write

697
00:37:59,800 --> 00:38:03,850
allocate so we can treat it if if

698
00:38:01,690 --> 00:38:05,590
there's a Miss we can do sort of the

699
00:38:03,850 --> 00:38:08,500
symmetric thing that we did with it with

700
00:38:05,590 --> 00:38:10,720
the hit which was create a new a new

701
00:38:08,500 --> 00:38:14,950
line possibly overwriting an existing

702
00:38:10,720 --> 00:38:17,470
line and then write in so we could so we

703
00:38:14,950 --> 00:38:19,870
could create that cache enter that cache

704
00:38:17,470 --> 00:38:23,290
line fetch it from memory and then do

705
00:38:19,870 --> 00:38:25,090
and then do the do the right ok so this

706
00:38:23,290 --> 00:38:28,510
is sort of symmetric to reads right that

707
00:38:25,090 --> 00:38:31,360
so every right if it misses when the

708
00:38:28,510 --> 00:38:34,300
right finishes the that block will be in

709
00:38:31,360 --> 00:38:36,640
the cache and if we do a subsequent read

710
00:38:34,300 --> 00:38:40,600
we get a hit ok so that's that's the

711
00:38:36,640 --> 00:38:44,610
reason you might want to do that the

712
00:38:40,600 --> 00:38:47,200
other option is just to don't allocate a

713
00:38:44,610 --> 00:38:49,000
an entry in the cache don't allocate a

714
00:38:47,200 --> 00:38:53,080
new line just write write the data

715
00:38:49,000 --> 00:38:54,760
directly to memory you don't really need

716
00:38:53,080 --> 00:38:57,460
to understand the distinction between

717
00:38:54,760 --> 00:39:00,730
these two things different caches use

718
00:38:57,460 --> 00:39:04,180
different policies for your own mental

719
00:39:00,730 --> 00:39:07,240
model a good model to use is just to

720
00:39:04,180 --> 00:39:09,220
assume write back write allocate so just

721
00:39:07,240 --> 00:39:11,620
assume that we won't we won't copy the

722
00:39:09,220 --> 00:39:13,780
data to disk if there's a hit we won't

723
00:39:11,620 --> 00:39:17,050
write it back to disk until the last

724
00:39:13,780 --> 00:39:19,180
possible minute and every time there's a

725
00:39:17,050 --> 00:39:21,760
write miss we'll create a new entry in

726
00:39:19,180 --> 00:39:24,470
the cache ok so that's that I think

727
00:39:21,760 --> 00:39:26,030
that's sort of the simplest model that

728
00:39:24,470 --> 00:39:28,310
it's a reason it's a reasonable model

729
00:39:26,030 --> 00:39:33,980
that you can use regardless of the

730
00:39:28,310 --> 00:39:35,690
particular cache implementation now in a

731
00:39:33,980 --> 00:39:37,369
real system so far we've only looked at

732
00:39:35,690 --> 00:39:42,890
we've only assumed that there's a single

733
00:39:37,369 --> 00:39:48,200
cache but in real systems there's

734
00:39:42,890 --> 00:39:55,480
multiple multiple caches so modern core

735
00:39:48,200 --> 00:39:55,480
i7 Haswell architecture from intel

736
00:39:55,510 --> 00:40:01,430
contains multiple processor cores so 4

737
00:39:59,690 --> 00:40:04,760
is a typical number for like desktop

738
00:40:01,430 --> 00:40:07,310
systems 8 8 to 12 it's typical for

739
00:40:04,760 --> 00:40:09,040
server class systems these processor

740
00:40:07,310 --> 00:40:11,170
cores can each execute their own

741
00:40:09,040 --> 00:40:16,540
independent instruction stream in

742
00:40:11,170 --> 00:40:19,400
parallel and each processor core can

743
00:40:16,540 --> 00:40:23,240
contains general-purpose registers which

744
00:40:19,400 --> 00:40:27,410
that's level 0 in the cache and then 2

745
00:40:23,240 --> 00:40:31,250
different kinds of l1 caches the data

746
00:40:27,410 --> 00:40:34,390
cache the l1d cache and the eye cache

747
00:40:31,250 --> 00:40:38,210
the L which is the instruction cache and

748
00:40:34,390 --> 00:40:40,010
these are these are fairly small 32 K

749
00:40:38,210 --> 00:40:42,890
bytes they're eight-way associative and

750
00:40:40,010 --> 00:40:47,540
they can be accessed in a very small

751
00:40:42,890 --> 00:40:51,130
number of cycles the next level of the

752
00:40:47,540 --> 00:40:56,410
hierarchy is is the l is an l2 cache

753
00:40:51,130 --> 00:41:00,170
which is still fairly small 256 K bytes

754
00:40:56,410 --> 00:41:04,369
same associativity and it has a slightly

755
00:41:00,170 --> 00:41:07,070
longer access time and and it's unified

756
00:41:04,369 --> 00:41:11,570
in the sense that the l2 cache contains

757
00:41:07,070 --> 00:41:14,859
both data and instructions ok so that's

758
00:41:11,570 --> 00:41:18,320
all within a single core on the chip and

759
00:41:14,859 --> 00:41:20,180
then also on the chip but external to

760
00:41:18,320 --> 00:41:24,080
all the cores and shared by all the

761
00:41:20,180 --> 00:41:28,220
cores is at l3 unified cache which is 8

762
00:41:24,080 --> 00:41:32,820
megabytes and 16 Way associative with an

763
00:41:28,220 --> 00:41:37,530
access time that's like 40 to 75 cycles

764
00:41:32,820 --> 00:41:40,530
so if if there's a Miss in l1 then the

765
00:41:37,530 --> 00:41:42,660
l1 sensor tries to send a request to l2

766
00:41:40,530 --> 00:41:45,300
to try to try to find the data in l2

767
00:41:42,660 --> 00:41:47,130
since l2 is a little bigger maybe maybe

768
00:41:45,300 --> 00:41:50,430
the data hasn't been flushed out of l2

769
00:41:47,130 --> 00:41:53,580
yet if they'll - can't find it it sends

770
00:41:50,430 --> 00:41:57,030
a request to l3 to see if they can find

771
00:41:53,580 --> 00:41:58,710
the data in l3 if l3 can't find it then

772
00:41:57,030 --> 00:42:05,070
it gives up and it goes off chip to

773
00:41:58,710 --> 00:42:09,090
memory yes question yes name memories is

774
00:42:05,070 --> 00:42:11,910
that's it's the DRAM built of DRAM chips

775
00:42:09,090 --> 00:42:14,420
it's it's separate it's in a separate

776
00:42:11,910 --> 00:42:18,240
separate set of chips on the motherboard

777
00:42:14,420 --> 00:42:21,630
connected by those that i/o bridge that

778
00:42:18,240 --> 00:42:24,440
we and the bus various buses then that

779
00:42:21,630 --> 00:42:24,440
we talked about last time

780
00:42:28,480 --> 00:42:33,280
and for all different for all of these

781
00:42:31,270 --> 00:42:41,500
different caches the block size is 64

782
00:42:33,280 --> 00:42:43,810
bytes now there's a number of different

783
00:42:41,500 --> 00:42:49,750
ways to think about the performance of

784
00:42:43,810 --> 00:42:52,180
caches my most most common way is using

785
00:42:49,750 --> 00:42:54,160
a metric called the Miss rate so what

786
00:42:52,180 --> 00:42:58,960
this is the fraction of references that

787
00:42:54,160 --> 00:43:03,160
Miss so we're very so I thought and it's

788
00:42:58,960 --> 00:43:05,109
1 minus the hit rate so typical for

789
00:43:03,160 --> 00:43:08,920
caches to work then this rate has to be

790
00:43:05,109 --> 00:43:12,810
pretty low and and fortunately because

791
00:43:08,920 --> 00:43:16,390
of locality these Miss rates are low

792
00:43:12,810 --> 00:43:19,359
another another metric is the hit time

793
00:43:16,390 --> 00:43:21,910
so if if we do have a hit in the cache

794
00:43:19,359 --> 00:43:24,160
how long does it actually take to sort

795
00:43:21,910 --> 00:43:25,570
of look up the you know do the lookup to

796
00:43:24,160 --> 00:43:27,990
determine that there was a hit and then

797
00:43:25,570 --> 00:43:32,619
return the value okay

798
00:43:27,990 --> 00:43:35,170
so for for l1 and in a Intel system this

799
00:43:32,619 --> 00:43:38,589
is four clock cycles ten clock cycles

800
00:43:35,170 --> 00:43:41,200
for l2 and then there's an additional

801
00:43:38,589 --> 00:43:42,880
Costas so you always have to pay the hit

802
00:43:41,200 --> 00:43:47,230
time right the hit time is the best you

803
00:43:42,880 --> 00:43:51,130
can do but if you have a Miss then it's

804
00:43:47,230 --> 00:43:52,390
you pay the hit time because you have to

805
00:43:51,130 --> 00:43:53,890
do the search and eventually you're

806
00:43:52,390 --> 00:43:56,800
going to return the word back to the

807
00:43:53,890 --> 00:43:58,480
requester but you have this additional

808
00:43:56,800 --> 00:44:02,140
cost which you have to go which is going

809
00:43:58,480 --> 00:44:04,540
to the memory to fetch the data okay so

810
00:44:02,140 --> 00:44:08,020
that that missed penalty that's so

811
00:44:04,540 --> 00:44:11,319
called miss penalty is on the order of

812
00:44:08,020 --> 00:44:13,300
hundreds of cycles for main memory but

813
00:44:11,319 --> 00:44:16,119
in other levels of the hierarchy it can

814
00:44:13,300 --> 00:44:17,700
be huge so the miss penalty if you if

815
00:44:16,119 --> 00:44:20,319
you have a cache in main memory

816
00:44:17,700 --> 00:44:24,690
that's caching blocks that are stored on

817
00:44:20,319 --> 00:44:24,690
disk the the miss penalty is enormous

818
00:44:27,540 --> 00:44:34,840
so it's kind of interesting if you think

819
00:44:30,910 --> 00:44:36,190
about it that performance is the

820
00:44:34,840 --> 00:44:38,260
performance of these systems is very

821
00:44:36,190 --> 00:44:41,620
sensitive to the miss rate much more

822
00:44:38,260 --> 00:44:47,500
sensitive than you would think and in

823
00:44:41,620 --> 00:45:07,930
fact 99% hit rate is twice as good as a

824
00:44:47,500 --> 00:45:10,480
97% hit rate yes yeah they hit so the

825
00:45:07,930 --> 00:45:12,880
question is does the hit time include

826
00:45:10,480 --> 00:45:15,690
the time tax to access the tag and yes

827
00:45:12,880 --> 00:45:19,210
so the hit time is the time it takes to

828
00:45:15,690 --> 00:45:23,940
to search to determine if that item is

829
00:45:19,210 --> 00:45:23,940
is is in the cache and then return it

830
00:45:33,569 --> 00:45:42,250
so basically we'll use it a title

831
00:45:36,670 --> 00:45:44,829
property yeah so the yeah so the the

832
00:45:42,250 --> 00:45:47,260
Miss the Miss penalty is the time it

833
00:45:44,829 --> 00:45:49,900
takes for the cash to fetch the data

834
00:45:47,260 --> 00:45:52,480
from memory so that's all the latency

835
00:45:49,900 --> 00:45:54,369
you know going across the buses the time

836
00:45:52,480 --> 00:45:56,680
it takes the memory to respond to the

837
00:45:54,369 --> 00:45:59,230
requests the time he takes the data to

838
00:45:56,680 --> 00:46:02,559
flow back over the buses back to the the

839
00:45:59,230 --> 00:46:04,599
cache so the time for a Miss is going to

840
00:46:02,559 --> 00:46:08,190
be the hit time plus the Miss penalty

841
00:46:04,599 --> 00:46:08,190
that clear

842
00:46:08,760 --> 00:46:14,770
so I mean imagine suppose there's a hit

843
00:46:12,730 --> 00:46:16,300
time of one cycle and a Miss penalty of

844
00:46:14,770 --> 00:46:20,470
100 cycles that those are reasonable

845
00:46:16,300 --> 00:46:24,640
numbers so the average access access

846
00:46:20,470 --> 00:46:28,359
time if you have 97% hits it's the hit

847
00:46:24,640 --> 00:46:30,970
time plus the percentage of misses times

848
00:46:28,359 --> 00:46:33,490
the Miss penalty so that's four cycles

849
00:46:30,970 --> 00:46:35,530
for the average access time but if we

850
00:46:33,490 --> 00:46:40,059
just increase the the hit rate by two

851
00:46:35,530 --> 00:46:44,339
percent the average access time drops by

852
00:46:40,059 --> 00:46:44,339
50 percent a factor of two

853
00:46:46,180 --> 00:46:51,140
all right so why why is this stuff

854
00:46:49,610 --> 00:46:54,890
important why why should you care about

855
00:46:51,140 --> 00:46:56,630
it so cash is that we as we've seen are

856
00:46:54,890 --> 00:47:01,330
these they're automatic they're all

857
00:46:56,630 --> 00:47:04,090
built in hardware there's no part of the

858
00:47:01,330 --> 00:47:06,830
sort of the visible instruction set that

859
00:47:04,090 --> 00:47:11,690
lets you manipulate caches and you're

860
00:47:06,830 --> 00:47:13,690
somewhere between codons programs so

861
00:47:11,690 --> 00:47:18,800
that it all happens behind the scenes

862
00:47:13,690 --> 00:47:20,240
automatically in hardware but if you

863
00:47:18,800 --> 00:47:21,740
know how care if you know about the

864
00:47:20,240 --> 00:47:23,420
existence of caches and you have this

865
00:47:21,740 --> 00:47:25,970
general idea of how you can work how

866
00:47:23,420 --> 00:47:30,110
they work then you can write code that's

867
00:47:25,970 --> 00:47:33,380
cash friendly in the sense that your

868
00:47:30,110 --> 00:47:36,880
code will have a higher higher miss rate

869
00:47:33,380 --> 00:47:41,920
than code that that isn't cash friendly

870
00:47:36,880 --> 00:47:44,780
so the idea is to you want to focus on

871
00:47:41,920 --> 00:47:46,970
making the common case go fast don't

872
00:47:44,780 --> 00:47:49,060
spend your time on code that sort of

873
00:47:46,970 --> 00:47:51,980
code that doesn't get execute very much

874
00:47:49,060 --> 00:47:54,830
so look at look at the most commonly

875
00:47:51,980 --> 00:47:56,360
called functions and then within those

876
00:47:54,830 --> 00:47:57,440
functions look at the inner loop to

877
00:47:56,360 --> 00:48:00,320
those functions because it's the inner

878
00:47:57,440 --> 00:48:02,210
loops that are executing the most right

879
00:48:00,320 --> 00:48:04,700
so you can as a first approximation you

880
00:48:02,210 --> 00:48:06,410
can just ignore sort of stuff if you

881
00:48:04,700 --> 00:48:08,750
have nested loops you can ignore stuff

882
00:48:06,410 --> 00:48:11,380
that's going on in the outer loops and

883
00:48:08,750 --> 00:48:13,370
just focus on the code in the inner loop

884
00:48:11,380 --> 00:48:15,610
now what you want to do is try to

885
00:48:13,370 --> 00:48:18,950
minimize the misses in the inner loop

886
00:48:15,610 --> 00:48:21,790
okay so repeated references to a

887
00:48:18,950 --> 00:48:23,990
variable is variables are good

888
00:48:21,790 --> 00:48:26,120
especially if those are local variables

889
00:48:23,990 --> 00:48:29,480
right so remember if you declare a local

890
00:48:26,120 --> 00:48:32,420
variable and see the compiler can put

891
00:48:29,480 --> 00:48:35,000
that in a register right if you're

892
00:48:32,420 --> 00:48:36,530
referencing global variables maybe not

893
00:48:35,000 --> 00:48:39,560
the compiler doesn't know what's going

894
00:48:36,530 --> 00:48:42,050
on so it can't put that rough it can't

895
00:48:39,560 --> 00:48:45,740
put the reference to that variable in a

896
00:48:42,050 --> 00:48:48,380
C in a register okay so repeated

897
00:48:45,740 --> 00:48:50,930
references to local variables stored on

898
00:48:48,380 --> 00:48:53,090
the stack are good because those will

899
00:48:50,930 --> 00:48:56,510
get turned into register accesses you'll

900
00:48:53,090 --> 00:48:58,790
never go to memory okay also stride one

901
00:48:56,510 --> 00:49:01,010
accesses two arrays are good

902
00:48:58,790 --> 00:49:03,770
and they're good because of the

903
00:49:01,010 --> 00:49:05,480
existence of these blocks right so the

904
00:49:03,770 --> 00:49:07,150
only way you'd know that stride one

905
00:49:05,480 --> 00:49:11,900
references our good is if you knew that

906
00:49:07,150 --> 00:49:14,960
caches have the 64-byte blocks okay so

907
00:49:11,900 --> 00:49:17,600
they and strive one one reference will

908
00:49:14,960 --> 00:49:21,530
have half the Miss rate as a stride to

909
00:49:17,600 --> 00:49:24,800
reference because if you're doing stride

910
00:49:21,530 --> 00:49:27,920
one references the first reference to a

911
00:49:24,800 --> 00:49:31,910
word in a block will miss but then

912
00:49:27,920 --> 00:49:33,560
subsequent references will hit right and

913
00:49:31,910 --> 00:49:35,230
you'll hit if you're doing a stride one

914
00:49:33,560 --> 00:49:38,360
reference you're going to hit every

915
00:49:35,230 --> 00:49:40,010
every word in that block if your drive

916
00:49:38,360 --> 00:49:41,150
if you're doing stride two references

917
00:49:40,010 --> 00:49:43,940
you're only going to hit every other

918
00:49:41,150 --> 00:49:45,920
word right so you'll only get you get

919
00:49:43,940 --> 00:49:54,860
sort of half the so you'll missed at

920
00:49:45,920 --> 00:49:57,620
twice the rate so the basically the

921
00:49:54,860 --> 00:50:00,770
point I want to make you is that our

922
00:49:57,620 --> 00:50:04,010
understanding of caches allow us to sort

923
00:50:00,770 --> 00:50:05,630
of quantify this this qualitative notion

924
00:50:04,010 --> 00:50:08,000
of locality that we developed the last

925
00:50:05,630 --> 00:50:09,800
time right the last time we looked at we

926
00:50:08,000 --> 00:50:13,610
said if it's doing stride one references

927
00:50:09,800 --> 00:50:15,740
that's good if it's if we're doing if

928
00:50:13,610 --> 00:50:18,440
we're accessing the same variable over

929
00:50:15,740 --> 00:50:20,510
and over that's good but if we

930
00:50:18,440 --> 00:50:26,900
understand caches now we can quantify it

931
00:50:20,510 --> 00:50:28,820
in terms of miss rate all right so let's

932
00:50:26,900 --> 00:50:30,320
finish up the rest of the class we're

933
00:50:28,820 --> 00:50:34,100
going to look at the performance impact

934
00:50:30,320 --> 00:50:35,540
of caches on your code okay and why why

935
00:50:34,100 --> 00:50:38,210
you need why you need to know about

936
00:50:35,540 --> 00:50:42,200
these things and that the impact that

937
00:50:38,210 --> 00:50:45,560
they can have so there's a very

938
00:50:42,200 --> 00:50:47,450
interesting function that's actually

939
00:50:45,560 --> 00:50:50,500
plotted on the cover of your your text

940
00:50:47,450 --> 00:50:52,610
book that we call the memory Mountain I

941
00:50:50,500 --> 00:50:55,160
learned about this from a graduate

942
00:50:52,610 --> 00:50:58,160
student here at Carnegie Mellon back in

943
00:50:55,160 --> 00:51:01,520
the 90s so you develop this notion there

944
00:50:58,160 --> 00:51:05,300
Tom Stricker and what it is that say the

945
00:51:01,520 --> 00:51:08,240
memory Mountain plots a measure called

946
00:51:05,300 --> 00:51:09,920
read through put or read bandwidth which

947
00:51:08,240 --> 00:51:12,150
is the number of bytes read from memory

948
00:51:09,920 --> 00:51:15,329
so if you have four

949
00:51:12,150 --> 00:51:18,510
have a loop and you're scanning over a

950
00:51:15,329 --> 00:51:21,260
vector so you have a vector of say say

951
00:51:18,510 --> 00:51:23,339
double words and you're reading those

952
00:51:21,260 --> 00:51:25,890
elements from a vector one after the

953
00:51:23,339 --> 00:51:27,690
other the read throughput is the number

954
00:51:25,890 --> 00:51:30,230
of megabytes per second that you can

955
00:51:27,690 --> 00:51:33,720
that you can perform that task at and

956
00:51:30,230 --> 00:51:36,539
the memory mountian plots read

957
00:51:33,720 --> 00:51:41,190
throughput as a function of the temporal

958
00:51:36,539 --> 00:51:43,619
and spatial locality in that loop okay

959
00:51:41,190 --> 00:51:46,700
so in a sense it's looking at a wide

960
00:51:43,619 --> 00:51:48,900
range of locality options or

961
00:51:46,700 --> 00:51:50,819
characteristics in a program and it's

962
00:51:48,900 --> 00:51:54,420
plotting the performance of that memory

963
00:51:50,819 --> 00:51:56,400
system on that across that range is a

964
00:51:54,420 --> 00:51:59,250
two-dimensional function so in some ways

965
00:51:56,400 --> 00:52:00,960
the memory Mountain is a kind of a

966
00:51:59,250 --> 00:52:03,630
fingerprint right every system has its

967
00:52:00,960 --> 00:52:05,279
own unique memory Mountain that we can

968
00:52:03,630 --> 00:52:12,270
measure right by writing a simple

969
00:52:05,279 --> 00:52:15,450
program and so the idea here is that to

970
00:52:12,270 --> 00:52:18,529
construct the memory Mountain we write a

971
00:52:15,450 --> 00:52:18,529
program called test

972
00:52:35,019 --> 00:52:38,019
shoot

973
00:52:50,970 --> 00:53:03,030
for some reason it's not okay all right

974
00:53:03,259 --> 00:53:09,269
so we believe when we build a memory

975
00:53:05,819 --> 00:53:14,240
Mountain we're given a vector that

976
00:53:09,269 --> 00:53:14,240
consists of a collection of double words

977
00:53:14,930 --> 00:53:22,769
and then we write a loop that reads

978
00:53:20,490 --> 00:53:25,640
those words that read some number of

979
00:53:22,769 --> 00:53:25,640
words in this case

980
00:53:41,950 --> 00:53:50,359
there we go so it reads it reads Elam's

981
00:53:47,829 --> 00:53:52,460
number of elements right so we've got

982
00:53:50,359 --> 00:53:57,079
each of these double word elements with

983
00:53:52,460 --> 00:54:02,989
a stride of stride okay so if we have a

984
00:53:57,079 --> 00:54:05,269
stride of one I know those kind of

985
00:54:02,989 --> 00:54:10,940
redundant him so if we have a stride of

986
00:54:05,269 --> 00:54:12,819
one then we'll we'll have our loop

987
00:54:10,940 --> 00:54:15,319
wheels will sort of loop through and

988
00:54:12,819 --> 00:54:18,529
read these elements until we've read

989
00:54:15,319 --> 00:54:21,829
elements number of those elements okay

990
00:54:18,529 --> 00:54:24,410
and then we'll do it again and then that

991
00:54:21,829 --> 00:54:28,640
warms up the cache then we do it again

992
00:54:24,410 --> 00:54:30,670
and do exactly the same thing so if

993
00:54:28,640 --> 00:54:34,099
we're doing this with a stride of two

994
00:54:30,670 --> 00:54:43,450
then we will be reading we would read

995
00:54:34,099 --> 00:54:43,450
this word zero or LM - LM 4 and so on

996
00:54:44,559 --> 00:54:49,880
okay so well then what all we're doing

997
00:54:47,509 --> 00:54:54,650
we're just for wide range of strides and

998
00:54:49,880 --> 00:54:57,890
a wide range of sizes we're scanning

999
00:54:54,650 --> 00:55:00,650
over this vector and just recording how

1000
00:54:57,890 --> 00:55:02,960
long it takes to do that read and then

1001
00:55:00,650 --> 00:55:07,789
convert we convert that into megabytes

1002
00:55:02,960 --> 00:55:09,200
per second and in order to I just wanted

1003
00:55:07,789 --> 00:55:11,869
to show you this this is we don't need

1004
00:55:09,200 --> 00:55:14,749
we're not going to go into detail about

1005
00:55:11,869 --> 00:55:17,690
this but this is actually how I

1006
00:55:14,749 --> 00:55:20,839
generated the the cover on the book and

1007
00:55:17,690 --> 00:55:22,789
in order to in order to use to exploit

1008
00:55:20,839 --> 00:55:24,680
the parallelism inside the intel

1009
00:55:22,789 --> 00:55:26,420
processor like you learned about last

1010
00:55:24,680 --> 00:55:28,759
week there's there's a lot of parallel

1011
00:55:26,420 --> 00:55:34,099
functional units in order to exploit

1012
00:55:28,759 --> 00:55:36,170
those i i i did 4x4 loop unrolling so

1013
00:55:34,099 --> 00:55:39,920
I'm actually doing sort of four scans in

1014
00:55:36,170 --> 00:55:42,469
parallel but the general idea is just

1015
00:55:39,920 --> 00:55:46,279
what I've showed you here and this this

1016
00:55:42,469 --> 00:55:48,650
4x4 this 4x4 loop unrolling is just an

1017
00:55:46,279 --> 00:55:50,479
optimization but I wanted to show it to

1018
00:55:48,650 --> 00:55:51,170
you because it actually it's the exact

1019
00:55:50,479 --> 00:55:53,270
same

1020
00:55:51,170 --> 00:55:56,090
principles you learned about last week

1021
00:55:53,270 --> 00:56:00,440
when Professor Brian talked about code

1022
00:55:56,090 --> 00:56:02,530
optimization so what we do is we we call

1023
00:56:00,440 --> 00:56:06,440
this test function with these various

1024
00:56:02,530 --> 00:56:08,540
ranges of Elam's and stride and then we

1025
00:56:06,440 --> 00:56:10,820
measure the performance and we get this

1026
00:56:08,540 --> 00:56:12,740
beautiful picture this beautiful

1027
00:56:10,820 --> 00:56:23,240
function to me it's beautiful I don't

1028
00:56:12,740 --> 00:56:27,740
know is it look beautiful to you so on

1029
00:56:23,240 --> 00:56:29,630
the Z our z axis is plotting read

1030
00:56:27,740 --> 00:56:34,850
throughput in megabytes per second

1031
00:56:29,630 --> 00:56:42,710
ranging from 2000 megabytes per second

1032
00:56:34,850 --> 00:56:48,470
up to 16,000 megabytes per second this

1033
00:56:42,710 --> 00:56:52,610
this axis is measuring is stride

1034
00:56:48,470 --> 00:56:59,660
so going from stride 1 up to stride 12

1035
00:56:52,610 --> 00:57:02,990
and this axis is so as we as we increase

1036
00:56:59,660 --> 00:57:07,750
stride we're decreasing the spatial

1037
00:57:02,990 --> 00:57:07,750
locality all right

1038
00:57:08,269 --> 00:57:17,179
and this axis is the size axis so we're

1039
00:57:12,769 --> 00:57:19,519
going from I think 16 K up to 128

1040
00:57:17,179 --> 00:57:21,049
megabytes so this is the number of

1041
00:57:19,519 --> 00:57:29,319
elements we're going to read each pass

1042
00:57:21,049 --> 00:57:32,479
through so as we as we increase the size

1043
00:57:29,319 --> 00:57:36,979
we're sort of decreasing the impact of

1044
00:57:32,479 --> 00:57:38,629
temporal locality because work as we

1045
00:57:36,979 --> 00:57:40,819
increase the size there's fewer and

1046
00:57:38,629 --> 00:57:46,539
fewer caches in our hierarchy can hold

1047
00:57:40,819 --> 00:57:49,069
all that data and so this so we've got

1048
00:57:46,539 --> 00:57:51,219
spatial locality decreasing in this

1049
00:57:49,069 --> 00:57:54,859
direction and temporal locality

1050
00:57:51,219 --> 00:57:57,619
decreasing in this direction so as a

1051
00:57:54,859 --> 00:58:00,469
programmer what you want to do you want

1052
00:57:57,619 --> 00:58:03,049
to be up here right good spatial

1053
00:58:00,469 --> 00:58:06,169
locality good temporal locality because

1054
00:58:03,049 --> 00:58:09,559
you can get like 14 gigabytes per second

1055
00:58:06,169 --> 00:58:12,799
measure Greek throughput you don't want

1056
00:58:09,559 --> 00:58:14,269
to be down here which is only about 100

1057
00:58:12,799 --> 00:58:16,399
megabytes per second where you're

1058
00:58:14,269 --> 00:58:18,399
reading out of memory right so the

1059
00:58:16,399 --> 00:58:23,149
difference between reading all of your

1060
00:58:18,399 --> 00:58:26,599
data from memory and we or reading it

1061
00:58:23,149 --> 00:58:28,659
from some part of the the caches is huge

1062
00:58:26,599 --> 00:58:31,489
it's enormous

1063
00:58:28,659 --> 00:58:33,769
ok so because you're 213 students you'll

1064
00:58:31,489 --> 00:58:38,119
be up here and all the students that

1065
00:58:33,769 --> 00:58:40,249
didn't take 213 they'll be down here and

1066
00:58:38,119 --> 00:58:43,519
I've actually had I've actually had

1067
00:58:40,249 --> 00:58:45,199
people several people write back to tell

1068
00:58:43,519 --> 00:58:47,749
me about their experiences you know in

1069
00:58:45,199 --> 00:58:49,909
internships and jobs after they lost an

1070
00:58:47,749 --> 00:58:53,599
emu where they were given some code that

1071
00:58:49,909 --> 00:58:55,609
that was down here and they recognized

1072
00:58:53,599 --> 00:58:57,919
the locality issues and they got it

1073
00:58:55,609 --> 00:59:00,250
you know better up here or close at

1074
00:58:57,919 --> 00:59:04,480
least better

1075
00:59:00,250 --> 00:59:05,980
so this this picture this so-called

1076
00:59:04,480 --> 00:59:08,440
memory mountain has all kinds of

1077
00:59:05,980 --> 00:59:10,150
interesting features first of all

1078
00:59:08,440 --> 00:59:13,359
there's these what I call ridges of

1079
00:59:10,150 --> 00:59:14,740
temporal locality where these ridges see

1080
00:59:13,359 --> 00:59:16,210
these Ridge lines if you think of this

1081
00:59:14,740 --> 00:59:19,619
is like a mountain you see this

1082
00:59:16,210 --> 00:59:21,849
Ridgeline and you see this Ridgeline and

1083
00:59:19,619 --> 00:59:23,560
here's another ridge line and then

1084
00:59:21,849 --> 00:59:25,060
here's a here's another one these

1085
00:59:23,560 --> 00:59:27,400
correspond to different levels in the

1086
00:59:25,060 --> 00:59:29,220
hierarchy so this this top Ridgeline is

1087
00:59:27,400 --> 00:59:34,210
where you're reading directly out of l1

1088
00:59:29,220 --> 00:59:35,530
and it should be perfectly flat and it's

1089
00:59:34,210 --> 00:59:38,140
so fast that we're getting like

1090
00:59:35,530 --> 00:59:42,010
measurement jitter performance jitter

1091
00:59:38,140 --> 00:59:43,930
right but it's it's and this little

1092
00:59:42,010 --> 00:59:45,369
drop-off here is a measurement artifact

1093
00:59:43,930 --> 00:59:47,710
it it should it shouldn't be there

1094
00:59:45,369 --> 00:59:52,630
should be it should be flat and go all

1095
00:59:47,710 --> 00:59:56,619
the way to the wall back here and then

1096
00:59:52,630 --> 00:59:59,590
here this this ridge line is where we're

1097
00:59:56,619 --> 01:00:02,980
accessing l2 this is what we're

1098
00:59:59,590 --> 01:00:06,580
accessing l3 and and here's what we're

1099
01:00:02,980 --> 01:00:08,470
accessing mostly from memory so you have

1100
01:00:06,580 --> 01:00:10,930
these ridges of temporal locality and

1101
01:00:08,470 --> 01:00:13,720
then you have these slopes of decreasing

1102
01:00:10,930 --> 01:00:17,349
spatial locality so you see the slope

1103
01:00:13,720 --> 01:00:19,570
here as work so as we're moving from the

1104
01:00:17,349 --> 01:00:23,980
from the top of the slope down to the

1105
01:00:19,570 --> 01:00:25,930
bottom we're decreasing our spatial

1106
01:00:23,980 --> 01:00:28,300
locality so we're getting less benefit

1107
01:00:25,930 --> 01:00:31,240
for these blocks that we're bringing in

1108
01:00:28,300 --> 01:00:33,609
right so you can see the we're getting

1109
01:00:31,240 --> 01:00:35,920
less benefit out of the cost that we

1110
01:00:33,609 --> 01:00:40,210
went through of importing of fetching

1111
01:00:35,920 --> 01:00:44,349
these blocks and once the stride hits

1112
01:00:40,210 --> 01:00:46,240
the block size now every reference is

1113
01:00:44,349 --> 01:00:47,740
hitting a different block and so and

1114
01:00:46,240 --> 01:00:49,390
then it flattens out then you get you're

1115
01:00:47,740 --> 01:00:55,180
getting nose benefit from spatial

1116
01:00:49,390 --> 01:00:57,820
locality and similarly here is where

1117
01:00:55,180 --> 01:01:02,140
this this this slope is where we're

1118
01:00:57,820 --> 01:01:04,480
reading from l3 and and and it flattens

1119
01:01:02,140 --> 01:01:08,080
out always if they always flatten out at

1120
01:01:04,480 --> 01:01:09,609
the at the block size which is a stride

1121
01:01:08,080 --> 01:01:12,220
these are double words right so it's

1122
01:01:09,609 --> 01:01:15,160
stride of 8

1123
01:01:12,220 --> 01:01:17,740
is 64 bytes so once you exceed a stride

1124
01:01:15,160 --> 01:01:19,450
of eight then you're no longer you're

1125
01:01:17,740 --> 01:01:24,640
missing every time in it in a different

1126
01:01:19,450 --> 01:01:25,990
block and there's this interesting this

1127
01:01:24,640 --> 01:01:29,670
one puzzled me for a while

1128
01:01:25,990 --> 01:01:32,520
you might be wondering like how come

1129
01:01:29,670 --> 01:01:37,230
like over here as we increase the size

1130
01:01:32,520 --> 01:01:39,630
we can sort of we're sort of getting the

1131
01:01:37,230 --> 01:01:41,890
we're sort of as we increase the size

1132
01:01:39,630 --> 01:01:44,710
we're doing most of our references out

1133
01:01:41,890 --> 01:01:49,090
of caches that are lower in the cache

1134
01:01:44,710 --> 01:01:53,410
hierarchy but except when we're doing

1135
01:01:49,090 --> 01:01:56,830
stride one references you can see all

1136
01:01:53,410 --> 01:02:01,180
the way up to right at the end right

1137
01:01:56,830 --> 01:02:05,260
before it exceeds the size of l3 it's

1138
01:02:01,180 --> 01:02:08,020
flat okay

1139
01:02:05,260 --> 01:02:09,640
and it's it's running at the l2 rate and

1140
01:02:08,020 --> 01:02:11,530
so here's the l1 rate and then it drops

1141
01:02:09,640 --> 01:02:15,220
off and then it's running at a constant

1142
01:02:11,530 --> 01:02:18,850
l2 rate until the data no longer sits in

1143
01:02:15,220 --> 01:02:22,870
l3 so I think what's going on here is

1144
01:02:18,850 --> 01:02:27,460
that the hardware the cache the cache

1145
01:02:22,870 --> 01:02:29,740
the l2 cache hardware is recognizing or

1146
01:02:27,460 --> 01:02:31,750
maybe it's an l1 but some some some

1147
01:02:29,740 --> 01:02:33,550
logic in that in the cache system is

1148
01:02:31,750 --> 01:02:36,610
recognizing the stride one reference

1149
01:02:33,550 --> 01:02:39,370
pattern because it sees all the

1150
01:02:36,610 --> 01:02:41,800
addresses it's wrecked it's recognizing

1151
01:02:39,370 --> 01:02:45,870
that stride one pattern and then it's

1152
01:02:41,800 --> 01:02:49,660
aggressively prefetching from l3 into l2

1153
01:02:45,870 --> 01:02:51,430
so that those so it's such an ahead of

1154
01:02:49,660 --> 01:02:53,830
time it's anticipating it saying look

1155
01:02:51,430 --> 01:02:55,900
I've gotten five stride one references

1156
01:02:53,830 --> 01:02:57,790
in a row I'm going to go grab a whole

1157
01:02:55,900 --> 01:03:00,130
bunch of blocks and load them all up

1158
01:02:57,790 --> 01:03:04,000
because by the principle of spatial

1159
01:03:00,130 --> 01:03:04,960
locality those blocks those blocks are

1160
01:03:04,000 --> 01:03:07,990
going to be referenced in the near

1161
01:03:04,960 --> 01:03:09,220
future so this was really neat and this

1162
01:03:07,990 --> 01:03:11,260
only happened within the last couple

1163
01:03:09,220 --> 01:03:16,630
years so the Intel engineers are always

1164
01:03:11,260 --> 01:03:19,510
hard at work and maybe by the time the

1165
01:03:16,630 --> 01:03:22,690
time we do the next the next edition of

1166
01:03:19,510 --> 01:03:24,940
the memory mountain those systems will

1167
01:03:22,690 --> 01:03:28,450
recognize stride 2 and you know other

1168
01:03:24,940 --> 01:03:30,190
stride patterns too but from this data

1169
01:03:28,450 --> 01:03:32,730
it appears that it's only recognizing

1170
01:03:30,190 --> 01:03:32,730
stride 1

1171
01:03:35,320 --> 01:03:43,640
okay so you can real we can improve the

1172
01:03:41,960 --> 01:03:47,080
spatial and temporal locality of our

1173
01:03:43,640 --> 01:03:49,880
programs in several different ways that

1174
01:03:47,080 --> 01:03:52,880
one way to improve the spatial locality

1175
01:03:49,880 --> 01:03:56,390
is to rearrange loops and I'll use

1176
01:03:52,880 --> 01:03:59,870
matrix multiplication as an example so

1177
01:03:56,390 --> 01:04:03,740
here's a sort of a simple matrix

1178
01:03:59,870 --> 01:04:07,760
multiplication in code where we're

1179
01:04:03,740 --> 01:04:12,080
multiplying a times B and adding it

1180
01:04:07,760 --> 01:04:17,540
we're taking what's in of the IJ element

1181
01:04:12,080 --> 01:04:21,020
of C and then to that we're adding the

1182
01:04:17,540 --> 01:04:26,330
sum the inner product of row I of a and

1183
01:04:21,020 --> 01:04:28,580
the row J a column J of B okay and then

1184
01:04:26,330 --> 01:04:31,940
so we're going through and for each IJ

1185
01:04:28,580 --> 01:04:37,150
in this matrix C we're computing an

1186
01:04:31,940 --> 01:04:40,640
inner product and then creating that sum

1187
01:04:37,150 --> 01:04:41,750
so we can actually turns out there's a

1188
01:04:40,640 --> 01:04:44,810
lot of different ways to do matrix

1189
01:04:41,750 --> 01:04:48,710
multiply and this is we can permute

1190
01:04:44,810 --> 01:04:51,590
these these loops in any of six

1191
01:04:48,710 --> 01:04:54,560
different possible permutations so this

1192
01:04:51,590 --> 01:04:56,690
is a permutation where it's I followed

1193
01:04:54,560 --> 01:05:02,330
by J followed by K but five other

1194
01:04:56,690 --> 01:05:04,460
possibilities are feasible and so we can

1195
01:05:02,330 --> 01:05:06,950
actually analyze those those different

1196
01:05:04,460 --> 01:05:10,370
permutations and predict which one will

1197
01:05:06,950 --> 01:05:11,750
have the best performance okay so what

1198
01:05:10,370 --> 01:05:16,970
we'll do is we'll look at the inner loop

1199
01:05:11,750 --> 01:05:19,100
and we'll look at the access pattern of

1200
01:05:16,970 --> 01:05:23,800
the inner loops and since the access

1201
01:05:19,100 --> 01:05:23,800
pattern on arrays C a and D

1202
01:05:24,620 --> 01:05:31,550
okay so let's look at the ijk

1203
01:05:29,030 --> 01:05:34,690
implementation that I just showed you so

1204
01:05:31,550 --> 01:05:39,050
as always we focus on the inner loop and

1205
01:05:34,690 --> 01:05:43,280
if you notice this inner loop is doing a

1206
01:05:39,050 --> 01:05:45,980
row wise access of column a and a column

1207
01:05:43,280 --> 01:05:49,910
wise access I'm sorry a row wise access

1208
01:05:45,980 --> 01:05:54,770
of array a and column wise access of a

1209
01:05:49,910 --> 01:05:56,630
row B so row wise of a column wise of B

1210
01:05:54,770 --> 01:05:58,610
we don't really care about C because

1211
01:05:56,630 --> 01:06:04,430
it's out it's not in the inner loop okay

1212
01:05:58,610 --> 01:06:06,370
so just ignore that so given our

1213
01:06:04,430 --> 01:06:10,130
assumption that we can hold in this case

1214
01:06:06,370 --> 01:06:13,010
we're assuming that we can hold for four

1215
01:06:10,130 --> 01:06:16,880
of these integer elements in a in one

1216
01:06:13,010 --> 01:06:18,710
block so the row wise access which has

1217
01:06:16,880 --> 01:06:21,590
good spatial locality will miss one

1218
01:06:18,710 --> 01:06:23,690
every four accesses okay the very first

1219
01:06:21,590 --> 01:06:25,790
reference will miss and then the next

1220
01:06:23,690 --> 01:06:27,080
three will hit and then the next

1221
01:06:25,790 --> 01:06:30,730
reference after that will hit a new

1222
01:06:27,080 --> 01:06:34,100
block okay so so one out of four

1223
01:06:30,730 --> 01:06:36,470
references to a will miss but because

1224
01:06:34,100 --> 01:06:40,580
the access pattern for B is column wise

1225
01:06:36,470 --> 01:06:43,160
every every every reference to B will

1226
01:06:40,580 --> 01:06:44,990
miss okay so the average number of

1227
01:06:43,160 --> 01:06:49,190
misses per loop iteration is one point

1228
01:06:44,990 --> 01:06:52,540
two five okay the j iik version is

1229
01:06:49,190 --> 01:06:52,540
exactly the same pattern

1230
01:06:54,510 --> 01:07:03,240
kij is a little different here we're

1231
01:06:59,040 --> 01:07:05,820
doing row-wise access of b and a row

1232
01:07:03,240 --> 01:07:07,859
wise access of c so that's good right so

1233
01:07:05,820 --> 01:07:11,220
now we've got stride one accesses on

1234
01:07:07,859 --> 01:07:12,869
both BMC and the reference to a is

1235
01:07:11,220 --> 01:07:17,400
outside of the loop so we don't care

1236
01:07:12,869 --> 01:07:20,550
about it so so both B and C will miss

1237
01:07:17,400 --> 01:07:22,500
one quarter of the time okay so the

1238
01:07:20,550 --> 01:07:25,890
total average number of misses per loop

1239
01:07:22,500 --> 01:07:29,750
iteration will be 0.5 that's pretty good

1240
01:07:25,890 --> 01:07:32,880
and I KJ has the same similar behavior

1241
01:07:29,750 --> 01:07:37,640
now jki is sort of the exact opposite

1242
01:07:32,880 --> 01:07:40,770
jki does column-wise access of a and

1243
01:07:37,640 --> 01:07:41,640
column wise access of c so right we know

1244
01:07:40,770 --> 01:07:46,230
that's a stinker

1245
01:07:41,640 --> 01:07:48,750
right and and we qualitatively know it's

1246
01:07:46,230 --> 01:07:52,440
bad and we can compute that it will miss

1247
01:07:48,750 --> 01:07:54,359
a one time per loop iteration so that

1248
01:07:52,440 --> 01:07:56,820
will be two total of two misses per

1249
01:07:54,359 --> 01:07:59,730
iteration and kji has the same bad

1250
01:07:56,820 --> 01:08:04,260
pattern okay so if we look at all these

1251
01:07:59,730 --> 01:08:10,800
permutations you can see that ijk and ji

1252
01:08:04,260 --> 01:08:14,850
k miss 1.25 has 1.25 mrs. K IJ has 0.5

1253
01:08:10,800 --> 01:08:17,880
misses and j ki has two misses so

1254
01:08:14,850 --> 01:08:20,759
clearly it looks like ki J and its

1255
01:08:17,880 --> 01:08:24,270
brethren are the best option the only

1256
01:08:20,759 --> 01:08:25,859
difference is that K ki J has this

1257
01:08:24,270 --> 01:08:27,930
additional store so there might be a

1258
01:08:25,859 --> 01:08:30,839
question that is that going to create is

1259
01:08:27,930 --> 01:08:34,980
that going to slow things down well it

1260
01:08:30,839 --> 01:08:38,040
turns out in systems and any kind

1261
01:08:34,980 --> 01:08:41,220
storage systems rights are much easier

1262
01:08:38,040 --> 01:08:44,160
to deal with them reads can it can you

1263
01:08:41,220 --> 01:08:45,720
think about why that might be true so

1264
01:08:44,160 --> 01:08:48,560
right you have a lot more flexibility

1265
01:08:45,720 --> 01:08:48,560
than you do with Ruiz

1266
01:08:49,779 --> 01:08:55,500
I mean yes

1267
01:08:56,179 --> 01:09:01,500
that's exactly so you can have options

1268
01:08:59,759 --> 01:09:04,889
you can do you can write back defer you

1269
01:09:01,500 --> 01:09:06,659
can defer writing until the value the

1270
01:09:04,889 --> 01:09:08,900
value that your written is actually used

1271
01:09:06,659 --> 01:09:11,549
but when you read an item you're stuck

1272
01:09:08,900 --> 01:09:13,799
you can't do anything until until you

1273
01:09:11,549 --> 01:09:15,750
get that data so it turns out that that

1274
01:09:13,799 --> 01:09:18,779
rights don't really that this additional

1275
01:09:15,750 --> 01:09:22,500
store doesn't really hurt us and so when

1276
01:09:18,779 --> 01:09:27,150
we measure these on a modern system you

1277
01:09:22,500 --> 01:09:30,719
can see that the the Kate kij which has

1278
01:09:27,150 --> 01:09:33,659
the the fewest number of misses has you

1279
01:09:30,719 --> 01:09:35,400
see we're getting like one miss Oh what

1280
01:09:33,659 --> 01:09:38,040
we're plotting here is cycles per inner

1281
01:09:35,400 --> 01:09:39,869
loop iteration so each each iteration is

1282
01:09:38,040 --> 01:09:44,250
taking about one cycle which is really

1283
01:09:39,869 --> 01:09:47,219
good this i JK pattern which is kind of

1284
01:09:44,250 --> 01:09:49,349
the intermediate 1.2 misses that's sort

1285
01:09:47,219 --> 01:09:52,739
of in between and the JK I which has two

1286
01:09:49,349 --> 01:09:54,089
misses per iteration is the worst ok so

1287
01:09:52,739 --> 01:09:56,869
what's interesting is we could actually

1288
01:09:54,089 --> 01:09:58,770
just by doing a little bit of analysis

1289
01:09:56,869 --> 01:10:01,320
simple analysis we could actually

1290
01:09:58,770 --> 01:10:07,050
predict what this what this graph would

1291
01:10:01,320 --> 01:10:08,760
look like ok in the in left last 10

1292
01:10:07,050 --> 01:10:10,820
minutes of the class we're going to look

1293
01:10:08,760 --> 01:10:13,560
at how to improve temporal locality now

1294
01:10:10,820 --> 01:10:15,630
so what we did with with when we

1295
01:10:13,560 --> 01:10:17,270
rearranged our loops in the matrix

1296
01:10:15,630 --> 01:10:21,780
multiplication what we were doing was in

1297
01:10:17,270 --> 01:10:22,949
improving our spatial locality right but

1298
01:10:21,780 --> 01:10:25,409
we didn't we didn't really do anything

1299
01:10:22,949 --> 01:10:26,849
to improve the temporal locality to

1300
01:10:25,409 --> 01:10:29,760
improve temporal locality you have to

1301
01:10:26,849 --> 01:10:31,560
use a technique called blocking and this

1302
01:10:29,760 --> 01:10:32,610
is important to understand because

1303
01:10:31,560 --> 01:10:35,610
you're going to need it in your cache

1304
01:10:32,610 --> 01:10:38,550
lab for one thing but it's also a very

1305
01:10:35,610 --> 01:10:39,989
general technique anytime you need any

1306
01:10:38,550 --> 01:10:46,380
time you're having issues with temporal

1307
01:10:39,989 --> 01:10:48,179
locality okay so we're not going to go

1308
01:10:46,380 --> 01:10:52,949
into too much detail this code but what

1309
01:10:48,179 --> 01:10:54,000
I did I rewrote the matrix multiply so

1310
01:10:52,949 --> 01:10:55,590
that it operates you know a

1311
01:10:54,000 --> 01:10:56,849
two-dimensional matrix that you can

1312
01:10:55,590 --> 01:10:59,250
really just think of it as a contiguous

1313
01:10:56,849 --> 01:11:01,380
array of bytes so I just rewrote this

1314
01:10:59,250 --> 01:11:03,900
code to operate on a contiguous array

1315
01:11:01,380 --> 01:11:06,630
one-dimensional array and then I'm doing

1316
01:11:03,900 --> 01:11:09,510
the indexing explicitly here so here at

1317
01:11:06,630 --> 01:11:11,550
CI x then plus J

1318
01:11:09,510 --> 01:11:14,789
this is an n-by-n matrix what I'm doing

1319
01:11:11,550 --> 01:11:17,190
is I'm I'm accessing the I'm computing

1320
01:11:14,789 --> 01:11:19,559
where the I throw starts and then I'm

1321
01:11:17,190 --> 01:11:27,599
going to the J column of that row and

1322
01:11:19,559 --> 01:11:29,869
then accessing that element all right so

1323
01:11:27,599 --> 01:11:32,659
let's but it's the same idea as before

1324
01:11:29,869 --> 01:11:35,429
so let's look at the Miss rate for this

1325
01:11:32,659 --> 01:11:39,119
this is just our original this is our

1326
01:11:35,429 --> 01:11:41,340
original unblocked matrix multiply so

1327
01:11:39,119 --> 01:11:46,289
what we're doing is we're we're

1328
01:11:41,340 --> 01:11:48,750
computing C 0 0 and we're doing that by

1329
01:11:46,289 --> 01:11:55,219
taking an inner product of row 0 and

1330
01:11:48,750 --> 01:11:57,869
column 0 oops so if you look at the

1331
01:11:55,219 --> 01:12:00,119
we're assuming that the cache the cache

1332
01:11:57,869 --> 01:12:02,730
blocks holds eight doubles and that the

1333
01:12:00,119 --> 01:12:04,909
matrix elements are doubles then we're

1334
01:12:02,730 --> 01:12:11,280
going to miss one eighth of the time

1335
01:12:04,909 --> 01:12:14,760
okay so in the first iteration we're

1336
01:12:11,280 --> 01:12:15,869
going to miss the first iteration does

1337
01:12:14,760 --> 01:12:18,420
any of these things

1338
01:12:15,869 --> 01:12:22,980
and since we're missing n over eight at

1339
01:12:18,420 --> 01:12:28,139
the time what we're missing one block

1340
01:12:22,980 --> 01:12:30,809
for every eight eight references for

1341
01:12:28,139 --> 01:12:34,619
each for the first iteration we're going

1342
01:12:30,809 --> 01:12:36,719
to miss n over eight and since there's n

1343
01:12:34,619 --> 01:12:42,420
for each element for each block I'm

1344
01:12:36,719 --> 01:12:44,219
sorry and then oh so this is the number

1345
01:12:42,420 --> 01:12:46,110
of blocks and the number of misses and

1346
01:12:44,219 --> 01:12:49,219
then we have n elements so that the

1347
01:12:46,110 --> 01:12:51,480
total number of misses is nine over n

1348
01:12:49,219 --> 01:12:56,219
divided by eight misses for the first

1349
01:12:51,480 --> 01:12:58,619
iteration okay the second iteration will

1350
01:12:56,219 --> 01:13:00,960
have the same number of misses because

1351
01:12:58,619 --> 01:13:04,469
of our assumptions about the the size of

1352
01:13:00,960 --> 01:13:06,329
this array so this these rows are way

1353
01:13:04,469 --> 01:13:08,579
too big to fit in the cache so we never

1354
01:13:06,329 --> 01:13:12,239
get any we don't get any temporal

1355
01:13:08,579 --> 01:13:15,449
locality okay so the total number of

1356
01:13:12,239 --> 01:13:17,010
misses is nine n over eight times the

1357
01:13:15,449 --> 01:13:19,289
number of elements that we're updating

1358
01:13:17,010 --> 01:13:22,010
which is N squared okay so our total

1359
01:13:19,289 --> 01:13:26,480
misses is nine over eight times and

1360
01:13:22,010 --> 01:13:30,710
and in cubed now let's rewrite the code

1361
01:13:26,480 --> 01:13:33,260
to use blocking and so you can look at

1362
01:13:30,710 --> 01:13:36,200
this code later but it's much simpler

1363
01:13:33,260 --> 01:13:39,680
just to just to look at it pictorially

1364
01:13:36,200 --> 01:13:43,190
so what what we're doing instead of

1365
01:13:39,680 --> 01:13:47,770
updating one element at a time we're

1366
01:13:43,190 --> 01:13:50,960
updating a sub block a B by B sub block

1367
01:13:47,770 --> 01:13:53,750
and we're doing that just totally

1368
01:13:50,960 --> 01:13:58,160
analogously to when our original case

1369
01:13:53,750 --> 01:14:01,070
where B equal one this this B by B sub

1370
01:13:58,160 --> 01:14:05,989
block in C is computed by taking an

1371
01:14:01,070 --> 01:14:10,280
inner product of the sub blocks of a set

1372
01:14:05,989 --> 01:14:12,950
of sub blocks in a with a set of sub

1373
01:14:10,280 --> 01:14:14,420
blocks in B and for each one of those

1374
01:14:12,950 --> 01:14:17,300
we're doing a little mini matrix

1375
01:14:14,420 --> 01:14:20,750
multiplication so we're taking we're

1376
01:14:17,300 --> 01:14:24,770
taking this sub block times this sub

1377
01:14:20,750 --> 01:14:29,140
block plus the second sub block of a

1378
01:14:24,770 --> 01:14:32,570
times the second sub block of of B plus

1379
01:14:29,140 --> 01:14:35,270
the third sub block of a times the third

1380
01:14:32,570 --> 01:14:37,190
sub block of B and so on okay so we're

1381
01:14:35,270 --> 01:14:39,290
doing the same inner product operation

1382
01:14:37,190 --> 01:14:41,360
but instead of scalars we're doing it

1383
01:14:39,290 --> 01:14:47,170
with these little sub these little tiny

1384
01:14:41,360 --> 01:14:49,580
matrices okay all right so let's look at

1385
01:14:47,170 --> 01:14:54,350
let's look at what happens to the Miss

1386
01:14:49,580 --> 01:15:02,830
rate when we do this so there's there's

1387
01:14:54,350 --> 01:15:08,050
n over B blocks in in any row or column

1388
01:15:02,830 --> 01:15:12,410
and since there's B squared items in

1389
01:15:08,050 --> 01:15:17,590
each block B times B there's B squared

1390
01:15:12,410 --> 01:15:21,219
over eight misses for each block okay

1391
01:15:17,590 --> 01:15:24,050
and so then and then since there's

1392
01:15:21,219 --> 01:15:27,290
there's n over B blocks in each matrix

1393
01:15:24,050 --> 01:15:33,469
and there's two matrices there's 2 - n

1394
01:15:27,290 --> 01:15:35,719
over B times B squared over 8 misses for

1395
01:15:33,469 --> 01:15:41,719
this first iteration so that that works

1396
01:15:35,719 --> 01:15:43,880
out to be an NB divided by 4 and the

1397
01:15:41,719 --> 01:15:47,060
second iteration has the same as the

1398
01:15:43,880 --> 01:15:50,119
same miss sort of same miss rate so that

1399
01:15:47,060 --> 01:15:53,060
the total number of misses is the number

1400
01:15:50,119 --> 01:15:59,449
of the number of misses for each

1401
01:15:53,060 --> 01:16:01,670
iteration x times the number of elements

1402
01:15:59,449 --> 01:16:06,170
and see that we're updating okay which

1403
01:16:01,670 --> 01:16:08,659
is n over B squared so that all works

1404
01:16:06,170 --> 01:16:13,940
out - it's still in its n cube divided

1405
01:16:08,659 --> 01:16:16,909
by 4 B so in our first case with no

1406
01:16:13,940 --> 01:16:19,909
blocking although that the number of

1407
01:16:16,909 --> 01:16:21,949
misses is asymptotically the same but

1408
01:16:19,909 --> 01:16:23,630
there's this pretty this big difference

1409
01:16:21,949 --> 01:16:26,840
in the constant factor so for no

1410
01:16:23,630 --> 01:16:29,540
blocking it's 9 over 8 for blocking it's

1411
01:16:26,840 --> 01:16:33,530
1 over 4b we're now we can we can just

1412
01:16:29,540 --> 01:16:34,820
sort of drive that down by by increasing

1413
01:16:33,530 --> 01:16:40,790
the block size so this gives us some

1414
01:16:34,820 --> 01:16:42,800
some control but we still we have we

1415
01:16:40,790 --> 01:16:44,480
can't make the block the blocks too big

1416
01:16:42,800 --> 01:16:48,760
because we need to fit three blocks in

1417
01:16:44,480 --> 01:16:48,760
the in cash at any one point in time

1418
01:16:49,210 --> 01:16:55,070
okay so the reason this is a dramatic

1419
01:16:51,739 --> 01:16:58,670
difference right and the reason for this

1420
01:16:55,070 --> 01:17:01,520
is that by doing the blocking we're sort

1421
01:16:58,670 --> 01:17:03,320
of exploiting once we load a block into

1422
01:17:01,520 --> 01:17:04,969
memory we're sort of reusing its items

1423
01:17:03,320 --> 01:17:09,349
over and over again so we're exploiting

1424
01:17:04,969 --> 01:17:10,880
more temporal locality and matrix

1425
01:17:09,349 --> 01:17:14,119
multiplication has this into this

1426
01:17:10,880 --> 01:17:16,340
implicit locality because the

1427
01:17:14,119 --> 01:17:20,929
computation is order n cubed but the

1428
01:17:16,340 --> 01:17:24,080
size of the data is N squared and so so

1429
01:17:20,929 --> 01:17:25,760
we must be reusing some data items right

1430
01:17:24,080 --> 01:17:28,099
the problem with our scaler approach is

1431
01:17:25,760 --> 01:17:32,390
that we we were when we were reusing

1432
01:17:28,099 --> 01:17:38,700
them they weren't in the cache okay

1433
01:17:32,390 --> 01:17:41,070
all right so the point that I wanted to

1434
01:17:38,700 --> 01:17:42,510
make with you is that cache memories

1435
01:17:41,070 --> 01:17:45,450
although they're they're sort of

1436
01:17:42,510 --> 01:17:48,480
built-in automatic hardware

1437
01:17:45,450 --> 01:17:51,500
storage devices and you can't really

1438
01:17:48,480 --> 01:17:54,260
control them if you know about them you

1439
01:17:51,500 --> 01:17:57,120
can take advantage of your knowledge and

1440
01:17:54,260 --> 01:18:00,090
exploit exploit them and make your code

1441
01:17:57,120 --> 01:18:04,670
run faster okay and the way you do this

1442
01:18:00,090 --> 01:18:04,670
is like I said focus on the inner loops

1443
01:18:04,700 --> 01:18:12,240
do is try to do try to accesses that our

1444
01:18:08,790 --> 01:18:14,520
stride one and try to maximize to to

1445
01:18:12,240 --> 01:18:17,370
maximize spatial locality and try to

1446
01:18:14,520 --> 01:18:19,050
maximize temporal locality by reusing

1447
01:18:17,370 --> 01:18:22,710
local variables which can then be put

1448
01:18:19,050 --> 01:18:24,660
into registers okay so that's it for

1449
01:18:22,710 --> 01:18:27,330
today good luck with your attack lab if

1450
01:18:24,660 --> 01:18:29,010
you haven't finished it and don't forget

1451
01:18:27,330 --> 01:18:31,370
to get started on cache labs on this

1452
01:18:29,010 --> 01:18:31,370
weekend

